import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
from scipy.sparse.linalg import svds

# Read the data from the CSV file
df = pd.read_csv("IF_MAIN6.csv")

# Create a pivot table to get transaction frequencies per sector
sector_frequency = df.pivot_table(
    index = "ACCT",
    columns = "Sector",
    values = "TRAN_AMT",  
    aggfunc = 'count', 
    fill_value = 0       
)

# Function for Cosine Similarity
def calculate_cosine_similarity(data):
    similarity_matrix = cosine_similarity(data)
    return similarity_matrix

# Function for Jaccard similarity 
def calculate_jaccard_similarity(data):
    data_matrix = csr_matrix(data)  # Convert to a sparse matrix for efficiency
    similarity_matrix = 1 - svds(data_matrix, k=10)[1]  # Efficient for large datasets
    return similarity_matrix

# Define a function to identify the dominant persona label for a customer
def identify_persona(customer_id, similarity_method="cosine"):
    if similarity_method == 'cosine':
        similarity_matrix = calculate_cosine_similarity(sector_frequency)
    elif similarity_method == 'jaccard':
        similarity_matrix = calculate_jaccard_similarity(sector_frequency)
    else:
        raise ValueError("Invalid similarity method")

    similarities = similarity_matrix[sector_frequency.index == customer_id].iloc[0]
    most_similar_customer = sector_frequency.index[similarities.idxmax()]
    dominant_sector = sector_frequency.loc[most_similar_customer].idxmax() 
    return dominant_sector

# Example usage (choose your preferred similarity method)
customer_id = "12345" 
persona_label = identify_persona(customer_id, similarity_method="cosine")
print(f"Customer {customer_id} Persona (Cosine Similarity): {persona_label}") 

persona_label = identify_persona(customer_id, similarity_method="jaccard")
print(f"Customer {customer_id} Persona (Jaccard Similarity): {persona_label}") 




import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
from scipy.sparse.linalg import svds
import numpy as np

# Read the data from the CSV file
df = pd.read_csv("IF_MAIN6.csv")

# Create a pivot table to get transaction frequencies per sector
sector_frequency = df.pivot_table(
    index="ACCT",
    columns="Sector",
    values="TRAN_AMT",
    aggfunc='count',
    fill_value=0
)

# Function for Cosine Similarity
def calculate_cosine_similarity(data):
    similarity_matrix = cosine_similarity(data)
    return similarity_matrix

# Function for Jaccard similarity 
def calculate_jaccard_similarity(data):
    data_matrix = csr_matrix(data)  # Convert to a sparse matrix for efficiency
    similarity_matrix = 1 - svds(data_matrix, k=10)[1]  # Efficient for large datasets
    return similarity_matrix

# Define a function to identify the dominant persona label for a customer
def identify_persona(customer_id, similarity_method="cosine"):
    # Ensure customer_id is an integer for indexing if it's a numeric type
    customer_id = int(customer_id) if customer_id.isdigit() else customer_id
    
    if similarity_method == 'cosine':
        similarity_matrix = calculate_cosine_similarity(sector_frequency.values)
    elif similarity_method == 'jaccard':
        similarity_matrix = calculate_jaccard_similarity(sector_frequency.values)
    else:
        raise ValueError("Invalid similarity method")
    
    # Convert sector_frequency.index (ACCT) to a list and find the index of the customer_id
    customer_index = list(sector_frequency.index).index(customer_id)
    
    # Get similarity scores for the specified customer_id
    similarities = similarity_matrix[customer_index]
    
    # Convert similarities to a Series to utilize idxmax()
    similarities_series = pd.Series(similarities, index=sector_frequency.index)
    
    # Find the most similar customer
    most_similar_customer = similarities_series.idxmax()
    
    # Determine the dominant sector for the most similar customer
    dominant_sector = sector_frequency.loc[[most_similar_customer]].idxmax(axis=1).values[0]
    
    return dominant_sector

# Example usage (choose your preferred similarity method)
customer_id = "12345"  # Ensure this matches an ACCT value in your CSV
persona_label = identify_persona(customer_id, similarity_method="cosine")
print(f"Customer {customer_id} Persona (Cosine Similarity): {persona_label}") 

persona_label = identify_persona(customer_id, similarity_method="jaccard")
print(f"Customer {customer_id} Persona (Jaccard Similarity): {persona_label}")






import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import SpectralClustering
from sklearn.preprocessing import StandardScaler

# Load your data
df = pd.read_csv("IF_MAIN6.csv")

# Create a pivot table to summarize transaction frequencies per sector for each account
sector_frequency = df.pivot_table(
    index="ACCT",
    columns="Sector",
    values="TRAN_AMT",
    aggfunc='count',
    fill_value=0
)

# Normalize the data
# It's a good practice to normalize the data when using cosine similarity
scaler = StandardScaler()
sector_frequency_scaled = scaler.fit_transform(sector_frequency)

# Compute the cosine similarity matrix
cosine_sim_matrix = cosine_similarity(sector_frequency_scaled)

# Apply Spectral Clustering using the precomputed cosine similarity matrix
# Adjust 'n_clusters' based on your specific needs or insights from the data
n_clusters = 5
spectral_clust = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', random_state=0)
clusters = spectral_clust.fit_predict(cosine_sim_matrix)

# Add the cluster labels to the original data
sector_frequency['Cluster'] = clusters

# Explore the resulting clusters
# This is a basic example of how to examine the clusters
for i in range(n_clusters):
    print(f"\nCluster {i} characteristics:")
    cluster_members = sector_frequency[sector_frequency['Cluster'] == i]
    print(cluster_members.mean())

# If needed, save the results to a new CSV file
# sector_frequency.to_csv("clustered_data.csv")

# Example: Identifying the cluster for a specific customer
customer_id = '12345'  # Replace with an actual ACCT number from your dataset
if customer_id in sector_frequency.index:
    customer_cluster = sector_frequency.loc[customer_id, 'Cluster']
    print(f"\nCustomer {customer_id} is in Cluster: {customer_cluster}")
else:
    print("\nCustomer ID not found in dataset.")
