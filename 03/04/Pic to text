Color Coding Information
Delivered Rate:
	â€¢	ðŸŸ¢ Green: Higher than 80%
	â€¢	ðŸŸ¡ Yellow: Between 80% - 20%
	â€¢	ðŸ”´ Red: Lower than 20%
Opened Rate:
	â€¢	ðŸŸ¢ Green: Higher than 40%
	â€¢	ðŸŸ¡ Yellow: Between 40% - 10%
	â€¢	ðŸ”´ Red: Lower than 10%
Clicked Rate:
	â€¢	ðŸŸ¢ Green: Higher than 20%
	â€¢	ðŸŸ¡ Yellow: Between 20% - 5%
	â€¢	ðŸ”´ Red: Lower than 5%
	4.	Format the text box by adju








from statsmodels.stats.outliers_influence import variance_inflation_factor
import pandas as pd

# Exclude GA_CUST_ID and Target variable from feature selection
features = final_df_scaled.drop(columns=['GA_CUST_ID', 'target_variable'])  # Ensure target variable name is correct

# Compute VIF for each feature
vif_data = pd.DataFrame()
vif_data["Feature"] = features.columns
vif_data["VIF"] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]

# Display VIF values
print("VIF values before removal:\n", vif_data)

# Drop features with VIF > 5 (Threshold can be adjusted)
high_vif_features = vif_data[vif_data["VIF"] > 5]["Feature"].tolist()
features = features.drop(columns=high_vif_features)

print("Removed features due to high collinearity:", high_vif_features)
















from sklearn.preprocessing import MinMaxScaler

# Preserve GA_CUST_ID
ga_cust_id = final_df[['GA_CUST_ID']]  # Keeping it separately

# Select all columns except GA_CUST_ID for scaling
columns_to_scale = final_df.drop(columns=['GA_CUST_ID']).columns

# Initialize MinMaxScaler
scaler = MinMaxScaler()

# Apply MinMaxScaler to numerical and one-hot encoded categorical columns
final_df_scaled = pd.DataFrame(scaler.fit_transform(final_df[columns_to_scale]), columns=columns_to_scale)

# Concatenate GA_CUST_ID back with the scaled data
final_df_scaled = pd.concat([ga_cust_id, final_df_scaled], axis=1)

# Display the updated DataFrame
print(final_df_scaled.head())















import pandas as pd
from sklearn.preprocessing import OneHotEncoder

# Sample DataFrame (Assuming final_df is already loaded)
# final_df contains numerical + categorical columns

# List of categorical columns (Assuming you already have this)
categorical_cols = ['col1', 'col2', 'col3']  # Replace with your actual categorical columns

# Initialize the OneHotEncoder
encoder = OneHotEncoder(drop='first', sparse=False)  # drop='first' to avoid dummy variable trap

# Fit and transform categorical columns
encoded_data = encoder.fit_transform(final_df[categorical_cols])

# Convert encoded data into a DataFrame with proper column names
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))

# Drop original categorical columns from final_df
final_df = final_df.drop(columns=categorical_cols)

# Concatenate encoded categorical columns back to final_df
final_df = pd.concat([final_df, encoded_df], axis=1)

# Display the updated DataFrame
print(final_df.head())










ty
import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import os
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import threading
from tqdm import tqdm

# Configure Tesseract OCR (Update if necessary)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ========================== IMAGE PROCESSING ========================== #

def preprocess_image(image):
    """Enhances image for OCR, handling noise, rotation, and contrast."""
    if len(image.shape) == 2:  
        gray = image
    elif image.shape[2] == 4:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)
    elif image.shape[2] == 3:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        raise ValueError("Unsupported image format")

    # Enhance contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)

    # Apply thresholding for better OCR
    _, thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# ========================== TABLE DETECTION ========================== #

def detect_table(image):
    """Detects tables in an image using contour detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)

    return lines is not None

def extract_table_from_image(image):
    """Extracts tabular data from an image and converts it into a Pandas DataFrame."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    rows = []

    for i in range(len(data['text'])):
        if data['text'][i].strip():
            rows.append([data['text'][i], data['left'][i], data['top'][i], data['width'][i], data['height'][i]])

    df = pd.DataFrame(rows, columns=['Text', 'Left', 'Top', 'Width', 'Height'])
    return df.sort_values(by=['Top', 'Left'])  # Maintain table structure

# ========================== PDF PROCESSING WITH FIX ========================== #

def process_pdf(file_path, progress_callback=None):
    """Extracts text & tables from PDFs, handling images separately with format fixes."""
    extracted_content = []

    try:
        with fitz.open(file_path) as doc:
            total_pages = len(doc)
            
            for page_num in tqdm(range(total_pages), desc="Processing PDF", leave=False):
                page = doc[page_num]

                if page.rotation != 0:
                    page.set_rotation(0)

                # Extract text directly from PDF
                text = page.get_text("text")
                if text.strip():
                    extracted_content.append(f"\nPage {page_num+1} Text:\n{text.strip()}")

                # Process images inside PDF
                image_list = page.get_images(full=True)
                for img_index, img in enumerate(image_list):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    nparr = np.frombuffer(image_bytes, np.uint8)
                    img_np = cv2.imdecode(nparr, cv2.IMREAD_UNCHANGED)

                    if img_np is not None:
                        # **Ensure image is converted to BGR (Fix OpenCV "Bad Number of Channels" error)**
                        if len(img_np.shape) == 2:
                            img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)
                        elif img_np.shape[2] == 4:
                            img_np = cv2.cvtColor(img_np, cv2.COLOR_BGRA2BGR)
                        elif img_np.shape[2] == 1:
                            img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)

                        # OCR Processing
                        processed_img = preprocess_image(img_np)
                        img_text = pytesseract.image_to_string(processed_img).strip()
                        extracted_content.append(f"\nPage {page_num+1} Image {img_index+1} OCR:\n{img_text}")

                if progress_callback:
                    progress_callback(page_num + 1, total_pages)

        return '\n'.join(extracted_content) if extracted_content else "No text found."
    except Exception as e:
        return f"Error processing PDF: {str(e)}"

# ========================== GUI ========================== #

class TextExtractorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("PDF & Image Text Extractor")
        self.root.geometry("1000x700")
        self.root.configure(bg='#f0f0f0')

        # Configure styles
        self.style = ttk.Style()
        self.style.configure('TButton', font=('Arial', 10), padding=5)
        self.style.configure('TProgressbar', thickness=10)

        # Create main container
        main_frame = ttk.Frame(root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # Control panel
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill=tk.X, pady=5)

        self.select_button = ttk.Button(control_frame, text="Select Files", command=self.select_files)
        self.select_button.pack(side=tk.LEFT, padx=5)

        self.extract_button = ttk.Button(control_frame, text="Extract Text", command=self.extract_text, state=tk.DISABLED)
        self.extract_button.pack(side=tk.LEFT, padx=5)

        # Progress bar
        self.progress_label = ttk.Label(control_frame, text="Progress: 0%")
        self.progress_label.pack(side=tk.LEFT, padx=10)

        self.progress = ttk.Progressbar(control_frame, orient="horizontal", length=300, mode="determinate")
        self.progress.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)

        # Text display area
        text_frame = ttk.Frame(main_frame)
        text_frame.pack(fill=tk.BOTH, expand=True)

        self.result_text = tk.Text(text_frame, wrap=tk.WORD, font=('Consolas', 11), undo=True, bg='white', padx=10, pady=10)
        self.result_text.pack(fill=tk.BOTH, expand=True)

        self.file_paths = []

    def select_files(self):
        self.file_paths = filedialog.askopenfilenames(filetypes=[("PDF & Image Files", "*.pdf;*.png;*.jpg;*.jpeg;*.bmp")])
        if self.file_paths:
            self.extract_button.config(state=tk.NORMAL)

    def extract_text(self):
        self.progress["value"] = 0
        self.result_text.delete("1.0", tk.END)

        def run_extraction():
            results = [process_pdf(file) for file in self.file_paths]
            for file, text in zip(self.file_paths, results):
                self.result_text.insert(tk.END, f"\nFile: {os.path.basename(file)}\n{text}\n")

        threading.Thread(target=run_extraction, daemon=True).start()

# ========================== RUN GUI ========================== #

if __name__ == "__main__":
    root = tk.Tk()
    app = TextExtractorApp(root)
    root.mainloop()








import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import os
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import threading
from tqdm import tqdm

# Configure Tesseract OCR (Update if necessary)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ========================== IMAGE PROCESSING ========================== #

def preprocess_image(image):
    """Enhances image for OCR, handling noise, rotation, and contrast."""
    if len(image.shape) == 2:  
        gray = image
    elif image.shape[2] == 4:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)
    elif image.shape[2] == 3:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        raise ValueError("Unsupported image format")

    # Enhance contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)

    # Apply thresholding for better OCR
    _, thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# ========================== TABLE DETECTION ========================== #

def detect_table(image):
    """Detects tables in an image using contour detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)

    return lines is not None

def extract_table_from_image(image):
    """Extracts tabular data from an image and converts it into a Pandas DataFrame."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    rows = []

    for i in range(len(data['text'])):
        if data['text'][i].strip():
            rows.append([data['text'][i], data['left'][i], data['top'][i], data['width'][i], data['height'][i]])

    df = pd.DataFrame(rows, columns=['Text', 'Left', 'Top', 'Width', 'Height'])
    return df.sort_values(by=['Top', 'Left'])  # Maintain table structure

# ========================== PDF PROCESSING WITH FIX ========================== #

def process_pdf(file_path, progress_callback=None):
    """Extracts text & tables from PDFs, handling images separately with format fixes."""
    extracted_content = []

    try:
        with fitz.open(file_path) as doc:
            total_pages = len(doc)
            
            for page_num in tqdm(range(total_pages), desc="Processing PDF", leave=False):
                page = doc[page_num]

                if page.rotation != 0:
                    page.set_rotation(0)

                # Extract text directly from PDF
                text = page.get_text("text")
                if text.strip():
                    extracted_content.append(f"\nPage {page_num+1} Text:\n{text.strip()}")

                # Process images inside PDF
                image_list = page.get_images(full=True)
                for img_index, img in enumerate(image_list):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    nparr = np.frombuffer(image_bytes, np.uint8)
                    img_np = cv2.imdecode(nparr, cv2.IMREAD_UNCHANGED)

                    if img_np is not None:
                        # **Ensure image is converted to BGR (Fix OpenCV "Bad Number of Channels" error)**
                        if len(img_np.shape) == 2:
                            img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)
                        elif img_np.shape[2] == 4:
                            img_np = cv2.cvtColor(img_np, cv2.COLOR_BGRA2BGR)
                        elif img_np.shape[2] == 1:
                            img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)

                        # OCR Processing
                        processed_img = preprocess_image(img_np)
                        img_text = pytesseract.image_to_string(processed_img).strip()
                        extracted_content.append(f"\nPage {page_num+1} Image {img_index+1} OCR:\n{img_text}")

                if progress_callback:
                    progress_callback(page_num + 1, total_pages)

        return '\n'.join(extracted_content) if extracted_content else "No text found."
    except Exception as e:
        return f"Error processing PDF: {str(e)}"

# ========================== GUI ========================== #

class TextExtractorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("PDF & Image Text Extractor")
        self.root.geometry("1000x700")
        self.root.configure(bg='#f0f0f0')

        # Configure styles
        self.style = ttk.Style()
        self.style.configure('TButton', font=('Arial', 10), padding=5)
        self.style.configure('TProgressbar', thickness=10)

        # Create main container
        main_frame = ttk.Frame(root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # Control panel
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill=tk.X, pady=5)

        self.select_button = ttk.Button(control_frame, text="Select Files", command=self.select_files)
        self.select_button.pack(side=tk.LEFT, padx=5)

        self.extract_button = ttk.Button(control_frame, text="Extract Text", command=self.extract_text, state=tk.DISABLED)
        self.extract_button.pack(side=tk.LEFT, padx=5)

        # Progress bar
        self.progress_label = ttk.Label(control_frame, text="Progress: 0%")
        self.progress_label.pack(side=tk.LEFT, padx=10)

        self.progress = ttk.Progressbar(control_frame, orient="horizontal", length=300, mode="determinate")
        self.progress.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)

        # Text display area
        text_frame = ttk.Frame(main_frame)
        text_frame.pack(fill=tk.BOTH, expand=True)

        self.result_text = tk.Text(text_frame, wrap=tk.WORD, font=('Consolas', 11), undo=True, bg='white', padx=10, pady=10)
        self.result_text.pack(fill=tk.BOTH, expand=True)

        self.file_paths = []

    def select_files(self):
        self.file_paths = filedialog.askopenfilenames(filetypes=[("PDF & Image Files", "*.pdf;*.png;*.jpg;*.jpeg;*.bmp")])
        if self.file_paths:
            self.extract_button.config(state=tk.NORMAL)

    def extract_text(self):
        self.progress["value"] = 0
        self.result_text.delete("1.0", tk.END)

        def run_extraction():
            results = [process_pdf(file) for file in self.file_paths]
            for file, text in zip(self.file_paths, results):
                self.result_text.insert(tk.END, f"\nFile: {os.path.basename(file)}\n{text}\n")

        threading.Thread(target=run_extraction, daemon=True).start()

# ========================== RUN GUI ========================== #

if __name__ == "__main__":
    root = tk.Tk()
    app = TextExtractorApp(root)
    root.mainloop()






https://github.com/UB-Mannheim/tesseract/wiki



import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import os
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import threading
from tqdm import tqdm

# Configure Tesseract OCR (Update if necessary)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ========================== IMAGE PROCESSING ========================== #

def preprocess_image(image):
    """Enhances image for OCR, handling noise, rotation, and contrast."""
    if len(image.shape) == 2:  
        gray = image
    elif image.shape[2] == 4:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)
    elif image.shape[2] == 3:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        raise ValueError("Unsupported image format")

    # Enhance contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)

    # Apply thresholding for better OCR
    _, thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# ========================== TABLE DETECTION ========================== #

def detect_table(image):
    """Detects tables in an image using contour detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)

    return lines is not None

def extract_table_from_image(image):
    """Extracts tabular data from an image and converts it into a Pandas DataFrame."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    rows = []

    for i in range(len(data['text'])):
        if data['text'][i].strip():
            rows.append([data['text'][i], data['left'][i], data['top'][i], data['width'][i], data['height'][i]])

    df = pd.DataFrame(rows, columns=['Text', 'Left', 'Top', 'Width', 'Height'])
    return df.sort_values(by=['Top', 'Left'])  # Maintain table structure

# ========================== OCR TEXT EXTRACTION ========================== #

def extract_text_from_image(image):
    """Extracts text from an image using Tesseract OCR."""
    return pytesseract.image_to_string(image, config="--oem 3 --psm 6").strip()

# ========================== PDF PROCESSING ========================== #

def process_pdf(file_path, progress_callback=None):
    """Extracts text & tables from PDFs, handling images separately."""
    extracted_content = []

    try:
        with fitz.open(file_path) as doc:
            total_pages = len(doc)
            
            for page_num in tqdm(range(total_pages), desc="Processing PDF", leave=False):
                page = doc[page_num]

                if page.rotation != 0:
                    page.set_rotation(0)

                # Extract text directly from PDF
                text = page.get_text("text")
                if text.strip():
                    extracted_content.append(f"\nPage {page_num+1} Text:\n{text.strip()}")

                # Process images inside PDF
                image_list = page.get_images(full=True)
                for img_index, img in enumerate(image_list):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    nparr = np.frombuffer(image_bytes, np.uint8)
                    img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                    if img_np is not None:
                        processed_img = preprocess_image(img_np)

                        if detect_table(processed_img):
                            table_df = extract_table_from_image(processed_img)
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1} (Table Detected):\n{table_df.to_csv(index=False)}")
                        else:
                            img_text = extract_text_from_image(processed_img)
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1}:\n{img_text}")

                if progress_callback:
                    progress_callback(page_num + 1, total_pages)

        return '\n'.join(extracted_content) if extracted_content else "No text found."
    except Exception as e:
        return f"Error processing PDF: {str(e)}"

# ========================== GUI ========================== #

class TextExtractorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("PDF & Image Text Extractor")
        self.root.geometry("1000x700")
        self.root.configure(bg='#f0f0f0')

        # Configure styles
        self.style = ttk.Style()
        self.style.configure('TButton', font=('Arial', 10), padding=5)
        self.style.configure('TProgressbar', thickness=10)

        # Create main container
        main_frame = ttk.Frame(root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # Control panel
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill=tk.X, pady=5)

        self.select_button = ttk.Button(control_frame, text="Select Files", command=self.select_files)
        self.select_button.pack(side=tk.LEFT, padx=5)

        self.extract_button = ttk.Button(control_frame, text="Extract Text", command=self.extract_text, state=tk.DISABLED)
        self.extract_button.pack(side=tk.LEFT, padx=5)

        # Progress bar
        self.progress_label = ttk.Label(control_frame, text="Progress: 0%")
        self.progress_label.pack(side=tk.LEFT, padx=10)

        self.progress = ttk.Progressbar(control_frame, orient="horizontal", length=300, mode="determinate")
        self.progress.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)

        # Text editor-like area
        text_frame = ttk.Frame(main_frame)
        text_frame.pack(fill=tk.BOTH, expand=True)

        self.result_text = tk.Text(text_frame, wrap=tk.WORD, font=('Consolas', 11), undo=True, bg='white', padx=10, pady=10)
        self.result_text.pack(fill=tk.BOTH, expand=True)

        self.file_paths = []

    def select_files(self):
        self.file_paths = filedialog.askopenfilenames(filetypes=[("PDF & Image Files", "*.pdf;*.png;*.jpg;*.jpeg;*.bmp")])
        if self.file_paths:
            self.extract_button.config(state=tk.NORMAL)

    def extract_text(self):
        self.progress["value"] = 0
        self.result_text.delete("1.0", tk.END)

        def run_extraction():
            results = [process_pdf(file) for file in self.file_paths]
            for file, text in zip(self.file_paths, results):
                self.result_text.insert(tk.END, f"\nFile: {os.path.basename(file)}\n{text}\n")

        threading.Thread(target=run_extraction, daemon=True).start()

# ========================== RUN GUI ========================== #

if __name__ == "__main__":
    root = tk.Tk()
    app = TextExtractorApp(root)
    root.mainloop()











new
import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import os
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import threading
from tqdm import tqdm

# Configure Tesseract OCR (Update if necessary)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ========================== IMAGE PROCESSING ========================== #

def preprocess_image(image):
    """Enhances image for OCR, handling noise, rotation, and contrast."""
    if len(image.shape) == 2:  
        gray = image
    elif image.shape[2] == 4:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)
    elif image.shape[2] == 3:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        raise ValueError("Unsupported image format")

    # Enhance contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)

    # Apply thresholding for better OCR
    _, thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# ========================== TABLE DETECTION ========================== #

def detect_table(image):
    """Detects tables in an image using contour detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)

    return lines is not None

def extract_table_from_image(image):
    """Extracts tabular data from an image and converts it into a Pandas DataFrame."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    rows = []

    for i in range(len(data['text'])):
        if data['text'][i].strip():
            rows.append([data['text'][i], data['left'][i], data['top'][i], data['width'][i], data['height'][i]])

    df = pd.DataFrame(rows, columns=['Text', 'Left', 'Top', 'Width', 'Height'])
    return df.sort_values(by=['Top', 'Left'])  # Maintain table structure

# ========================== OCR TEXT EXTRACTION ========================== #

def extract_text_from_image(image):
    """Extracts text from an image using Tesseract OCR."""
    return pytesseract.image_to_string(image, config="--oem 3 --psm 6").strip()

# ========================== PDF PROCESSING ========================== #

def process_pdf(file_path, progress_callback=None):
    """Extracts text & tables from PDFs, handling images separately."""
    extracted_content = []

    try:
        with fitz.open(file_path) as doc:
            total_pages = len(doc)
            
            for page_num in tqdm(range(total_pages), desc="Processing PDF", leave=False):
                page = doc[page_num]

                if page.rotation != 0:
                    page.set_rotation(0)

                # Extract text directly from PDF
                text = page.get_text("text")
                if text.strip():
                    extracted_content.append(f"\nPage {page_num+1} Text:\n{text.strip()}")

                # Process images inside PDF
                image_list = page.get_images(full=True)
                for img_index, img in enumerate(image_list):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    nparr = np.frombuffer(image_bytes, np.uint8)
                    img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                    if img_np is not None:
                        processed_img = preprocess_image(img_np)

                        if detect_table(processed_img):
                            table_df = extract_table_from_image(processed_img)
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1} (Table Detected):\n{table_df.to_csv(index=False)}")
                        else:
                            img_text = extract_text_from_image(processed_img)
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1}:\n{img_text}")

                if progress_callback:
                    progress_callback(page_num + 1, total_pages)

        return '\n'.join(extracted_content) if extracted_content else "No text found."
    except Exception as e:
        raise RuntimeError(f"PDF processing failed: {str(e)}")

# ========================== GUI ========================== #

class TextExtractorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("PDF & Image Text Extractor")
        self.root.geometry("700x500")

        self.select_button = tk.Button(root, text="Select PDF or Image", command=self.select_files)
        self.select_button.pack(pady=5)

        self.extract_button = tk.Button(root, text="Extract Text & Tables", command=self.extract_text, state=tk.DISABLED)
        self.extract_button.pack(pady=5)

        self.progress_label = tk.Label(root, text="Progress: 0%")
        self.progress_label.pack(pady=5)

        self.progress = ttk.Progressbar(root, orient="horizontal", length=500, mode="determinate")
        self.progress.pack(pady=5)

        self.result_text = tk.Text(root, height=15, width=80)
        self.result_text.pack(pady=10)

        self.file_paths = []

    def select_files(self):
        self.file_paths = filedialog.askopenfilenames(filetypes=[("PDF & Image Files", "*.pdf;*.png;*.jpg;*.jpeg;*.bmp")])
        if self.file_paths:
            self.extract_button.config(state=tk.NORMAL)

    def update_progress(self, current, total):
        percent = int((current / total) * 100)
        self.progress["value"] = percent
        self.progress_label.config(text=f"Progress: {percent}%")
        self.root.update_idletasks()

    def extract_text(self):
        self.progress["value"] = 0
        self.result_text.delete("1.0", tk.END)

        def run_extraction():
            results = [process_pdf(file, self.update_progress) for file in self.file_paths]
            for file, text in zip(self.file_paths, results):
                self.result_text.insert(tk.END, f"\nFile: {os.path.basename(file)}\n{text}\n")

        threading.Thread(target=run_extraction, daemon=True).start()

# ========================== RUN GUI ========================== #

if __name__ == "__main__":
    root = tk.Tk()
    app = TextExtractorApp(root)
    root.mainloop()









import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import os
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import threading
from tqdm import tqdm

# Configure Tesseract OCR (Update if necessary)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ========================== IMAGE PROCESSING ========================== #

def preprocess_image(image):
    """Enhances image for OCR, handling noise, rotation, and contrast."""
    if len(image.shape) == 2:  
        gray = image
    elif image.shape[2] == 4:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)
    elif image.shape[2] == 3:  
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        raise ValueError("Unsupported image format")

    # Enhance contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)

    # Apply thresholding for better OCR
    _, thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# ========================== TABLE DETECTION ========================== #

def detect_table(image):
    """Detects tables in an image using contour detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)

    return lines is not None

def extract_table_from_image(image):
    """Extracts tabular data from an image and converts it into a Pandas DataFrame."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    rows = []

    for i in range(len(data['text'])):
        if data['text'][i].strip():
            rows.append([data['text'][i], data['left'][i], data['top'][i], data['width'][i], data['height'][i]])

    df = pd.DataFrame(rows, columns=['Text', 'Left', 'Top', 'Width', 'Height'])
    return df.sort_values(by=['Top', 'Left'])  # Maintain table structure

# ========================== PDF PROCESSING ========================== #

def process_pdf(file_path, progress_callback=None):
    """Extracts text & tables from PDFs, handling images separately."""
    extracted_content = []

    try:
        with fitz.open(file_path) as doc:
            total_pages = len(doc)
            
            for page_num in tqdm(range(total_pages), desc="Processing PDF", leave=False):
                page = doc[page_num]

                if page.rotation != 0:
                    page.set_rotation(0)

                text = page.get_text("text")
                if text.strip():
                    extracted_content.append(f"\nPage {page_num+1} Text:\n{text.strip()}")

                # Process images inside PDF
                image_list = page.get_images(full=True)
                for img_index, img in enumerate(image_list):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    nparr = np.frombuffer(image_bytes, np.uint8)
                    img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                    if img_np is not None:
                        processed_img = preprocess_image(img_np)

                        if detect_table(processed_img):
                            table_df = extract_table_from_image(processed_img)
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1} (Table Detected):\n{table_df.to_csv(index=False)}")
                        else:
                            img_text = pytesseract.image_to_string(processed_img).strip()
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1}:\n{img_text}")

                if progress_callback:
                    progress_callback(page_num + 1, total_pages)

        return '\n'.join(extracted_content) if extracted_content else "No text found."
    except Exception as e:
        raise RuntimeError(f"PDF processing failed: {str(e)}")

# ========================== GUI ========================== #

class TextExtractorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("PDF & Image Table Extractor")
        self.root.geometry("700x500")

        self.select_button = tk.Button(root, text="Select PDF File", command=self.select_files)
        self.select_button.pack(pady=5)

        self.extract_button = tk.Button(root, text="Extract Text & Tables", command=self.extract_text, state=tk.DISABLED)
        self.extract_button.pack(pady=5)

        self.progress_label = tk.Label(root, text="Progress: 0%")
        self.progress_label.pack(pady=5)

        self.progress = ttk.Progressbar(root, orient="horizontal", length=500, mode="determinate")
        self.progress.pack(pady=5)

        self.result_text = tk.Text(root, height=15, width=80)
        self.result_text.pack(pady=10)

        self.file_paths = []

    def select_files(self):
        self.file_paths = filedialog.askopenfilenames(filetypes=[("PDF Files", "*.pdf")])
        if self.file_paths:
            self.extract_button.config(state=tk.NORMAL)

    def update_progress(self, current, total):
        percent = int((current / total) * 100)
        self.progress["value"] = percent
        self.progress_label.config(text=f"Progress: {percent}%")
        self.root.update_idletasks()

    def extract_text(self):
        self.progress["value"] = 0
        self.result_text.delete("1.0", tk.END)

        def run_extraction():
            results = [process_pdf(file, self.update_progress) for file in self.file_paths]
            for file, text in zip(self.file_paths, results):
                self.result_text.insert(tk.END, f"\nFile: {os.path.basename(file)}\n{text}\n")

        threading.Thread(target=run_extraction, daemon=True).start()

# ========================== RUN GUI ========================== #

if __name__ == "__main__":
    root = tk.Tk()
    app = TextExtractorApp(root)
    root.mainloop()













ltst
import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import os
import threading
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
from tqdm import tqdm
import pandas as pd
from concurrent.futures import ThreadPoolExecutor

# Configure Tesseract OCR (Update if necessary)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ========================== IMAGE PROCESSING ========================== #

def preprocess_image(image):
    """Enhances image for OCR, handling noise, rotation, and low contrast."""
    try:
        if len(image.shape) == 2:  
            gray = image
        elif image.shape[2] == 4:  
            gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)
        elif image.shape[2] == 3:  
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            raise ValueError("Unsupported image format")

        # Deskew the image
        coords = np.column_stack(np.where(gray > 0))
        angle = cv2.minAreaRect(coords)[-1]
        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle
        (h, w) = gray.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        gray = cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

        # Enhance contrast
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        # Apply thresholding
        _, thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        return thresh
    except Exception as e:
        raise RuntimeError(f"Image preprocessing failed: {str(e)}")

# ========================== TABLE DETECTION ========================== #

def detect_table(image):
    """Detects tables in an image using contour & line detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)

    return lines is not None

def extract_table_from_image(image):
    """Extracts tabular data from an image and returns it as a Pandas DataFrame."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    rows = []
    
    for i in range(len(data['text'])):
        if data['text'][i].strip():
            rows.append([data['text'][i], data['left'][i], data['top'][i], data['width'][i], data['height'][i]])

    df = pd.DataFrame(rows, columns=['Text', 'Left', 'Top', 'Width', 'Height'])
    return df.sort_values(by=['Top', 'Left'])  # Sort to maintain table structure

# ========================== PDF PROCESSING ========================== #

def process_pdf(file_path, progress_callback=None):
    """Extracts text & images from PDFs, handling rotation & OCR if needed."""
    extracted_content = []

    try:
        with fitz.open(file_path) as doc:
            total_pages = len(doc)
            
            for page_num in tqdm(range(total_pages), desc="Processing PDF", leave=False):
                page = doc[page_num]

                if page.rotation != 0:
                    page.set_rotation(0)

                text = page.get_text("text")
                if text.strip():
                    extracted_content.append(f"\nPage {page_num+1} Text:\n{text.strip()}")

                # Process images if no text found
                image_list = page.get_images(full=True)
                for img_index, img in enumerate(image_list):
                    xref = img[0]
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    nparr = np.frombuffer(image_bytes, np.uint8)
                    img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                    if img_np is not None:
                        processed_img = preprocess_image(img_np)

                        if detect_table(processed_img):
                            table_df = extract_table_from_image(processed_img)
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1} (Table Detected):\n{table_df.to_csv(index=False)}")
                        else:
                            img_text = pytesseract.image_to_string(processed_img).strip()
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1}:\n{img_text}")

                if progress_callback:
                    progress_callback(page_num + 1, total_pages)

        return '\n'.join(extracted_content) if extracted_content else "No text found."
    except Exception as e:
        raise RuntimeError(f"PDF processing failed: {str(e)}")

# ========================== GUI ========================== #

class TextExtractorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Ultimate PDF & Image Text Extractor")
        self.root.geometry("700x500")

        self.select_button = tk.Button(root, text="Select Files", command=self.select_files)
        self.select_button.pack(pady=5)

        self.extract_button = tk.Button(root, text="Extract Text", command=self.extract_text, state=tk.DISABLED)
        self.extract_button.pack(pady=5)

        self.progress_label = tk.Label(root, text="Progress: 0%")
        self.progress_label.pack(pady=5)

        self.progress = ttk.Progressbar(root, orient="horizontal", length=500, mode="determinate")
        self.progress.pack(pady=5)

        self.result_text = tk.Text(root, height=15, width=80)
        self.result_text.pack(pady=10)

        self.file_paths = []

    def select_files(self):
        self.file_paths = filedialog.askopenfilenames(filetypes=[("PDF & Images", "*.pdf;*.png;*.jpg;*.jpeg;*.bmp")])
        if self.file_paths:
            self.extract_button.config(state=tk.NORMAL)

    def update_progress(self, current, total):
        percent = int((current / total) * 100)
        self.progress["value"] = percent
        self.progress_label.config(text=f"Progress: {percent}%")
        self.root.update_idletasks()

    def extract_text(self):
        self.progress["value"] = 0
        self.result_text.delete("1.0", tk.END)

        def run_extraction():
            results = [process_pdf(file, self.update_progress) for file in self.file_paths]
            for file, text in zip(self.file_paths, results):
                self.result_text.insert(tk.END, f"\nFile: {os.path.basename(file)}\n{text}\n")

        threading.Thread(target=run_extraction, daemon=True).start()

# ========================== RUN GUI ========================== #

if __name__ == "__main__":
    root = tk.Tk()
    app = TextExtractorApp(root)
    root.mainloop()







import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import os
import threading
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
from tqdm import tqdm
import pandas as pd
from concurrent.futures import ThreadPoolExecutor

# Configure Tesseract OCR (update this if needed)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ========================== IMAGE PROCESSING ========================== #

def preprocess_image(image):
    """Enhances image for OCR, handling noise, rotation, and low contrast."""
    try:
        # Convert CMYK to BGR if needed
        if len(image.shape) == 2:  
            gray = image
        elif image.shape[2] == 4:  
            gray = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)
        elif image.shape[2] == 3:  
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            raise ValueError("Unsupported image format")

        # Deskew the image (detects and corrects rotated text)
        coords = np.column_stack(np.where(gray > 0))
        angle = cv2.minAreaRect(coords)[-1]
        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle
        (h, w) = gray.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        gray = cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

        # Contrast enhancement using CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        # Apply thresholding for OCR optimization
        _, thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        return thresh
    except Exception as e:
        raise RuntimeError(f"Image preprocessing failed: {str(e)}")

# ========================== TABLE DETECTION ========================== #

def detect_table(image):
    """Detects tables in an image using contour & line detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)

    if lines is not None:
        horizontal, vertical = 0, 0
        for line in lines:
            x1, y1, x2, y2 = line[0]
            if abs(y2 - y1) < 10 and abs(x2 - x1) > 50:
                horizontal += 1
            elif abs(x2 - x1) < 10 and abs(y2 - y1) > 50:
                vertical += 1
        return horizontal > 3 and vertical > 3
    return False

# ========================== TEXT EXTRACTION ========================== #

def get_text_from_image(image, lang="eng+hin"):
    """Extracts text from an image using Tesseract OCR."""
    try:
        text = pytesseract.image_to_string(image, config="--oem 3 --psm 6", lang=lang).strip()
        return text if text else "No text found."
    except Exception as e:
        raise RuntimeError(f"Text extraction failed: {str(e)}")

# ========================== PDF PROCESSING ========================== #

def process_pdf(file_path, progress_callback=None):
    """Extracts text & images from PDFs, handling rotation & OCR if needed."""
    extracted_content = []

    try:
        with fitz.open(file_path) as doc:
            for page_num in tqdm(range(len(doc)), desc="Processing PDF", leave=False):
                page = doc[page_num]

                if page.rotation != 0:
                    page.set_rotation(0)

                text = page.get_text("text")
                if text.strip():
                    extracted_content.append(f"\nPage {page_num+1} Text:\n{text.strip()}")
                else:
                    image_list = page.get_images(full=True)
                    for img_index, img in enumerate(image_list):
                        xref = img[0]
                        base_image = doc.extract_image(xref)
                        image_bytes = base_image["image"]
                        nparr = np.frombuffer(image_bytes, np.uint8)
                        img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                        if img_np is not None:
                            processed_img = preprocess_image(img_np)
                            img_text = get_text_from_image(processed_img)
                            extracted_content.append(f"\nPage {page_num+1} Image {img_index+1}:\n{img_text}")

                if progress_callback:
                    progress_callback(page_num + 1, len(doc))

        return '\n'.join(extracted_content) if extracted_content else "No text found."
    except Exception as e:
        raise RuntimeError(f"PDF processing failed: {str(e)}")

# ========================== BATCH FILE PROCESSING ========================== #

def process_files(file_paths):
    """Processes multiple files concurrently using threading."""
    results = {}

    def process_single_file(file_path):
        results[file_path] = process_pdf(file_path) if file_path.endswith(".pdf") else get_text_from_image(cv2.imread(file_path))

    with ThreadPoolExecutor(max_workers=5) as executor:
        executor.map(process_single_file, file_paths)

    return results

# ========================== GUI ========================== #

class TextExtractorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Ultimate PDF & Image Text Extractor")
        self.root.geometry("600x400")

        self.select_button = tk.Button(root, text="Select Files", command=self.select_files)
        self.select_button.pack(pady=5)

        self.extract_button = tk.Button(root, text="Extract Text", command=self.extract_text, state=tk.DISABLED)
        self.extract_button.pack(pady=5)

        self.progress = ttk.Progressbar(root, orient="horizontal", length=400, mode="determinate")
        self.progress.pack(pady=5)

        self.result_text = tk.Text(root, height=15, width=70)
        self.result_text.pack(pady=10)

        self.file_paths = []

    def select_files(self):
        self.file_paths = filedialog.askopenfilenames(filetypes=[("PDF & Images", "*.pdf;*.png;*.jpg;*.jpeg;*.bmp")])
        if self.file_paths:
            self.extract_button.config(state=tk.NORMAL)

    def extract_text(self):
        self.progress["value"] = 0
        self.result_text.delete("1.0", tk.END)

        def run_extraction():
            results = process_files(self.file_paths)
            for file, text in results.items():
                self.result_text.insert(tk.END, f"\nFile: {os.path.basename(file)}\n{text}\n")

        threading.Thread(target=run_extraction, daemon=True).start()

# ========================== RUN GUI ========================== #

if __name__ == "__main__":
    root = tk.Tk()
    app = TextExtractorApp(root)
    root.mainloop()









2.
import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import io
import os
import tempfile

def preprocess_image(image):
    """Enhances image for better OCR results."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # Reduce noise
    thresh = cv2.adaptiveThreshold(blurred, 255, 
                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                   cv2.THRESH_BINARY, 11, 2)
    return thresh

def detect_table(image):
    """Detects if an image contains a table using contour detection."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edged = cv2.Canny(gray, 50, 150)
    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    return len(contours) > 10  # Arbitrary threshold for table detection

def get_words_from_image(image):
    """Extracts words from image using Tesseract OCR with dynamic confidence threshold."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    conf_scores = [int(conf) for conf in data['conf'] if conf.isdigit()]
    avg_conf = np.mean(conf_scores) if conf_scores else 50
    threshold = max(avg_conf * 0.8, 40)  # Dynamic confidence threshold
    
    words = []
    for i in range(len(data['text'])):
        if int(data['conf'][i]) > threshold:
            text = data['text'][i].strip()
            if text:
                words.append({
                    'text': text,
                    'left': data['left'][i],
                    'top': data['top'][i],
                    'right': data['left'][i] + data['width'][i],
                    'bottom': data['top'][i] + data['height'][i]
                })
    return words

def get_words_from_pdf(page):
    """Extracts words from PDF page with coordinates, handling rotated text."""
    words = page.get_text("words", flags=fitz.TEXT_DEHYPHENATE | fitz.TEXT_PRESERVE_LIGATURES)
    return [{
        'text': word[4],
        'left': word[0],
        'top': word[1],
        'right': word[2],
        'bottom': word[3]
    } for word in words if word[4].strip()]

def group_into_rows(words, y_threshold=5):
    """Groups words into rows based on vertical positions."""
    if not words:
        return []
    sorted_words = sorted(words, key=lambda x: x['top'])
    rows = []
    current_row = [sorted_words[0]]
    current_y = sorted_words[0]['top']
    
    for word in sorted_words[1:]:
        if abs(word['top'] - current_y) <= y_threshold:
            current_row.append(word)
        else:
            rows.append(current_row)
            current_row = [word]
            current_y = word['top']
    rows.append(current_row)
    return rows

def group_into_cells(row, x_threshold=20):
    """Groups words in a row into table cells."""
    sorted_row = sorted(row, key=lambda x: x['left'])
    cells = []
    if not sorted_row:
        return cells
    current_text = sorted_row[0]['text']
    current_right = sorted_row[0]['right']
    
    for word in sorted_row[1:]:
        if word['left'] - current_right <= x_threshold:
            current_text += ' ' + word['text']
            current_right = word['right']
        else:
            cells.append(current_text)
            current_text = word['text']
            current_right = word['right']
    cells.append(current_text)
    return cells

def is_table(rows, consistency=0.8):
    """Determines if the structure resembles a table."""
    if len(rows) < 1:
        return False
    cell_counts = [len(row) for row in rows]
    max_count = max(set(cell_counts), key=cell_counts.count)
    matches = sum(1 for count in cell_counts if count == max_count)
    return (matches / len(cell_counts)) >= consistency

def process_image(image_path):
    """Processes an image file for text/table extraction."""
    img = cv2.imread(image_path)
    processed_img = preprocess_image(img)
    
    if detect_table(processed_img):
        words = get_words_from_image(processed_img)
        rows = group_into_rows(words)
        table_data = [group_into_cells(row) for row in rows]
        return '\n'.join([','.join(f'"{cell}"' for cell in row) for row in table_data])
    else:
        return pytesseract.image_to_string(processed_img).strip()

def pdf_to_text(pdf_path):
    """Extracts text and tables from PDF including embedded images."""
    full_text = []
    
    with fitz.open(pdf_path) as doc:
        for page_num in range(len(doc)):
            page = doc[page_num]
            words = get_words_from_pdf(page)
            rows = group_into_rows(words, y_threshold=2)
            table_data = [group_into_cells(row, x_threshold=10) for row in rows]
            
            if is_table(table_data):
                full_text.append(f"\nPage {page_num+1} Table:\n")
                full_text.append('\n'.join([','.join(f'"{cell}"' for cell in row) for row in table_data]))
            else:
                full_text.append(f"\nPage {page_num+1} Text:\n")
                full_text.append(page.get_text().strip())
            
            # Process images in the PDF page
            for img_index, img in enumerate(page.get_images(full=True)):
                xref = img[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image["image"]
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as temp_file:
                    temp_file.write(image_bytes)
                    temp_path = temp_file.name
                
                try:
                    img_text = process_image(temp_path)
                    full_text.append(f"\nPage {page_num+1} Image {img_index+1}:\n{img_text}")
                finally:
                    os.remove(temp_path)
    
    return '\n'.join(full_text)

def file_to_text(file_path):
    """Main function that handles both images and PDFs."""
    if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):
        return process_image(file_path)
    elif file_path.lower().endswith('.pdf'):
        return pdf_to_text(file_path)
    else:
        raise ValueError("Unsupported file format")

# Example Usage
result = file_to_text("path/to/your/file.pdf")  # or .png/.jpg
print(result)









import cv2
import pytesseract
from pytesseract import Output
import numpy as np
import fitz  # PyMuPDF
import io
import os
import tempfile

def preprocess_image(image):
    """Enhances image for better OCR results."""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
    return thresh

def get_words_from_image(image):
    """Extracts words from image using Tesseract OCR."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    words = []
    n_boxes = len(data['text'])
    for i in range(n_boxes):
        if int(data['conf'][i]) > 60:
            text = data['text'][i].strip()
            if text:
                words.append({
                    'text': text,
                    'left': data['left'][i],
                    'top': data['top'][i],
                    'right': data['left'][i] + data['width'][i],
                    'bottom': data['top'][i] + data['height'][i]
                })
    return words

def get_words_from_pdf(page):
    """Extracts words from PDF page with coordinates."""
    words = page.get_text("words")
    return [{
        'text': word[4],
        'left': word[0],
        'top': word[1],
        'right': word[2],
        'bottom': word[3]
    } for word in words if word[4].strip()]

def group_into_rows(words, y_threshold=5):
    """Groups words into rows based on vertical positions."""
    if not words:
        return []
    sorted_words = sorted(words, key=lambda x: x['top'])
    rows = []
    current_row = [sorted_words[0]]
    current_y = sorted_words[0]['top']
    
    for word in sorted_words[1:]:
        if abs(word['top'] - current_y) <= y_threshold:
            current_row.append(word)
        else:
            rows.append(current_row)
            current_row = [word]
            current_y = word['top']
    rows.append(current_row)
    return rows

def group_into_cells(row, x_threshold=20):
    """Groups words in a row into table cells."""
    sorted_row = sorted(row, key=lambda x: x['left'])
    cells = []
    if not sorted_row:
        return cells
    current_text = sorted_row[0]['text']
    current_right = sorted_row[0]['right']
    
    for word in sorted_row[1:]:
        if word['left'] - current_right <= x_threshold:
            current_text += ' ' + word['text']
            current_right = word['right']
        else:
            cells.append(current_text)
            current_text = word['text']
            current_right = word['right']
    cells.append(current_text)
    return cells

def is_table(rows, consistency=0.8):
    """Determines if the structure resembles a table."""
    if len(rows) < 1:
        return False
    cell_counts = [len(row) for row in rows]
    max_count = max(set(cell_counts), key=cell_counts.count)
    matches = sum(1 for count in cell_counts if count == max_count)
    return (matches / len(cell_counts)) >= consistency

def process_image(image_path):
    """Processes an image file for text/table extraction."""
    img = cv2.imread(image_path)
    processed_img = preprocess_image(img)
    words = get_words_from_image(processed_img)
    rows = group_into_rows(words)
    table_data = [group_into_cells(row) for row in rows]
    
    if is_table(table_data):
        return '\n'.join([','.join(f'"{cell}"' for cell in row) for row in table_data])
    else:
        return pytesseract.image_to_string(processed_img).strip()

def pdf_to_text(pdf_path):
    """Extracts text and tables from PDF including embedded images."""
    full_text = []
    doc = fitz.open(pdf_path)
    
    for page_num, page in enumerate(doc):
        # Process text layer
        words = get_words_from_pdf(page)
        rows = group_into_rows(words, y_threshold=2)  # Tighter threshold for PDF coordinates
        table_data = [group_into_cells(row, x_threshold=10) for row in rows]
        
        if is_table(table_data):
            full_text.append(f"\nPage {page_num+1} Table:\n")
            full_text.append('\n'.join([','.join(f'"{cell}"' for cell in row) for row in table_data]))
        else:
            full_text.append(f"\nPage {page_num+1} Text:\n")
            full_text.append(page.get_text().strip())
        
        # Process images in the PDF page
        image_list = page.get_images()
        for img_index, img in enumerate(image_list):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as temp_file:
                temp_file.write(image_bytes)
                temp_path = temp_file.name
            
            try:
                img_text = process_image(temp_path)
                full_text.append(f"\nPage {page_num+1} Image {img_index+1}:\n{img_text}")
            finally:
                os.remove(temp_path)
    
    return '\n'.join(full_text)

def file_to_text(file_path):
    """Main function that handles both images and PDFs."""
    if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):
        return process_image(file_path)
    elif file_path.lower().endswith('.pdf'):
        return pdf_to_text(file_path)
    else:
        raise ValueError("Unsupported file format")

# Example Usage
result = file_to_text("path/to/your/file.pdf")  # or .png/.jpg
print(result)









import cv2
import pytesseract
from pytesseract import Output
import numpy as np

def preprocess_image(image_path):
    """Enhances image for better OCR results."""
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
    return thresh

def get_words(image):
    """Extracts words and their coordinates using Tesseract."""
    data = pytesseract.image_to_data(image, output_type=Output.DICT)
    words = []
    n_boxes = len(data['text'])
    for i in range(n_boxes):
        if int(data['conf'][i]) > 60:  # Filter low-confidence detections
            text = data['text'][i].strip()
            if text:
                words.append({
                    'text': text,
                    'left': data['left'][i],
                    'top': data['top'][i],
                    'right': data['left'][i] + data['width'][i],
                    'bottom': data['top'][i] + data['height'][i]
                })
    return words

def group_into_rows(words, y_threshold=5):
    """Groups words into rows based on y-coordinates."""
    if not words:
        return []
    sorted_words = sorted(words, key=lambda x: x['top'])
    rows = []
    current_row = [sorted_words[0]]
    current_y = sorted_words[0]['top']
    
    for word in sorted_words[1:]:
        if abs(word['top'] - current_y) <= y_threshold:
            current_row.append(word)
        else:
            rows.append(current_row)
            current_row = [word]
            current_y = word['top']
    rows.append(current_row)
    return rows

def group_into_cells(row, x_threshold=20):
    """Merges words in a row into cells based on x-coordinates."""
    sorted_row = sorted(row, key=lambda x: x['left'])
    cells = []
    if not sorted_row:
        return cells
    current_text = sorted_row[0]['text']
    current_right = sorted_row[0]['right']
    
    for word in sorted_row[1:]:
        if word['left'] - current_right <= x_threshold:
            current_text += ' ' + word['text']
            current_right = word['right']
        else:
            cells.append(current_text)
            current_text = word['text']
            current_right = word['right']
    cells.append(current_text)
    return cells

def is_table(rows, consistency=0.8):
    """Determines if the data resembles a table."""
    if len(rows) < 1:
        return False
    cell_counts = [len(row) for row in rows]
    max_count = max(set(cell_counts), key=cell_counts.count)
    matches = sum(1 for count in cell_counts if count == max_count)
    return (matches / len(cell_counts)) >= consistency

def image_to_text(image_path):
    """Main function to convert image to text or table."""
    processed_img = preprocess_image(image_path)
    words = get_words(processed_img)
    rows = group_into_rows(words)
    table_data = [group_into_cells(row) for row in rows]
    
    if is_table(table_data):
        # Format as CSV
        csv = '\n'.join([','.join(f'"{cell}"' for cell in row) for row in table_data])
        return csv
    else:
        # Return plain text
        text = pytesseract.image_to_string(processed_img)
        return text.strip()

# Example Usage
image_path = 'path/to/your/image.png'
result = image_to_text(image_path)
print(result)
