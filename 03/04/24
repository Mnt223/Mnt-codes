import pandas as pd
import plotly.graph_objs as go
from dash import Dash, html, dcc
from dash.dependencies import Input, Output
import datetime

# Sample DataFrame setup
# Replace this with your actual data loading logic
data = {
    'Transaction Date': pd.date_range(start='2022-01-01', periods=120, freq='D'),
    'Transaction Amount': pd.np.random.randint(100, 500, size=120),
    'POS': pd.np.random.choice([0, 1], size=120)
}
df = pd.DataFrame(data)
df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])

app = Dash(__name__)

app.layout = html.Div(children=[
    html.H1('Credit Card Spend Analysis Dashboard', style={'color': 'white', 'backgroundColor': 'black'}),
    
    html.Div([
        dcc.RadioItems(
            id='time-period-selector',
            options=[
                {'label': '1D', 'value': '1D'},
                {'label': '1W', 'value': '1W'},
                {'label': '1M', 'value': '1M'},
                {'label': '1Y', 'value': '1Y'},
            ],
            value='1M',  # Default value
            labelStyle={'display': 'inline-block', 'color': 'white'},
            style={'padding': '20px'}
        ),
        dcc.DatePickerRange(
            id='date-picker-range',
            start_date=datetime.date.today() - datetime.timedelta(days=30),
            end_date=datetime.date.today(),
            calendar_orientation='horizontal',
        ),
    ], style={'backgroundColor': 'black'}),
    
    dcc.Graph(id='time-series-chart'),
])

@app.callback(
    Output('time-series-chart', 'figure'),
    [Input('time-period-selector', 'value'),
     Input('date-picker-range', 'start_date'),
     Input('date-picker-range', 'end_date')]
)
def update_chart(selected_period, start_date, end_date):
    filtered_df = df.copy()  # Placeholder for actual filtering based on inputs
    
    # Example filtering logic (to be replaced with actual logic based on 'selected_period')
    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)
    filtered_df = filtered_df[(filtered_df['Transaction Date'] >= start_date) & (filtered_df['Transaction Date'] <= end_date)]

    # Creating the time series plot
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(x=filtered_df['Transaction Date'], y=filtered_df['Transaction Amount'], mode='lines', name='Overall', line=dict(color='red')))
    if 'POS' in filtered_df.columns:
        pos_df = filtered_df[filtered_df['POS'] == 1]
        fig.add_trace(go.Scatter(x=pos_df['Transaction Date'], y=pos_df['Transaction Amount'], mode='lines', name='POS', line=dict(color='yellow')))
    
    # Customizing the plot appearance
    fig.update_layout(plot_bgcolor='black', paper_bgcolor='black', font=dict(color='white'))
    
    return fig

if __name__ == '__main__':
    app.run_server(debug=True)








tt
import pandas as pd
import plotly.graph_objs as go
from dash import Dash, html, dcc

# Load your DataFrame
# df = pd.read_csv('your_data.csv')  # Replace with your actual data loading logic

# Ensure the 'Transaction Date' is a datetime type
df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])

# Aggregate the transaction amounts by date for Overall and POS
df_overall = df.groupby('Transaction Date')['Transaction Amount'].sum().reset_index(name='Overall')
df_pos = df[df['POS'] == 1].groupby('Transaction Date')['Transaction Amount'].sum().reset_index(name='POS')

# Create the time series plot
fig_time_series = go.Figure()

# Add trace for Overall with red color
fig_time_series.add_trace(go.Scatter(
    x=df_overall['Transaction Date'], 
    y=df_overall['Overall'], 
    mode='lines',
    line=dict(color='red', width=2),
    fill='tozeroy',  # Fill to zero on the y-axis
    fillcolor='rgba(255, 0, 0, 0.5)',  # Red fill with transparency for shadow effect
    hoverinfo='y',  # Show only the y value on hover
    name='Overall'
))

# Add trace for POS with yellow color
fig_time_series.add_trace(go.Scatter(
    x=df_pos['Transaction Date'], 
    y=df_pos['POS'], 
    mode='lines',
    line=dict(color='yellow', width=2),
    fill='tozeroy',  # Fill to zero on the y-axis
    fillcolor='rgba(255, 255, 0, 0.5)',  # Yellow fill with transparency for shadow effect
    hoverinfo='y',  # Show only the y value on hover
    name='POS'
))

# Update the layout to customize the look
fig_time_series.update_layout(
    title='Transaction Amount Over Time',
    xaxis_title='Transaction Date',
    yaxis_title='Transaction Amount',
    hovermode='x',
    plot_bgcolor='black',  # Set the plot background to black
    paper_bgcolor='rgb(40, 40, 40)',  # Set the paper background to dark grey
    font=dict(color='white'),  # Set the font color to white
    legend=dict(
        font=dict(
            size=10,
            color='white'
        ),
    ),
    xaxis=dict(
        gridcolor='darkgrey',  # Set grid color to dark grey
        color='white'  # Set axis text color to white
    ),
    yaxis=dict(
        gridcolor='darkgrey',  # Set grid color to dark grey
        color='white'  # Set axis text color to white
    )
)

# Create a Dash application
app = Dash(__name__)

# Define the app layout
app.layout = html.Div(children=[
    html.H1('Credit Card Spend Analysis Dashboard', style={'color': 'white', 'backgroundColor': 'black'}),
    dcc.Graph(id='time-series-chart', figure=fig_time_series, style={'backgroundColor': 'black'}),
    # More components will be added here later
], style={'backgroundColor': 'rgb(40, 40, 40)'})

# Run the server
if __name__ == '__main__':
    app.run_server(debug=True)










# Import necessary libraries
import pandas as pd
import plotly.express as px
from dash import Dash, html, dcc

# Assuming you have loaded your DataFrame as `df`
# df = pd.read_csv('your_data.csv')  # or however you acquire your data

# Preprocessing: Ensure Transaction Date is a datetime type and aggregate the data
df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])
agg_df = df.groupby(['Transaction Date', 'General Category']).agg({'Transaction Amount': 'sum'}).reset_index()

# Create the time series plot
fig_time_series = px.line(agg_df, x='Transaction Date', y='Transaction Amount', color='General Category', title='Transaction Amount Over Time')

# Create a Dash application
app = Dash(__name__)

# Define the app layout to include the time series plot
app.layout = html.Div(children=[
    html.H1('Credit Card Spend Analysis Dashboard'),
    dcc.Graph(id='time-series-chart', figure=fig_time_series),
    # You will add more components to the layout later
])

# Run the application
if __name__ == '__main__':
    app.run_server(debug=True)
















import pandas as pd
import plotly.graph_objs as go
from dash import Dash, html, dcc, Input, Output

# Load your DataFrame here
# df = pd.read_csv('your_data.csv')

app = Dash(__name__)

app.layout = html.Div(children=[
    html.H1('Credit Card Spend Analysis'),
    
    # Time Series Plot
    dcc.Graph(id='time-series-chart'),
    
    # Bar Charts for Categories, Age Groups, Top Merchants
    html.Div(children=[
        dcc.Graph(id='category-bar-chart'),
        dcc.Graph(id='age-group-bar-chart'),
        dcc.Graph(id='merchant-bar-chart'),
    ], style={'display': 'flex', 'flex-direction': 'row'}),
    
    # ... include other dashboard components as needed ...
])

@app.callback(
    Output('time-series-chart', 'figure'),
    # Input(...) - define any inputs you need for interactive components
)
def update_time_series(/* parameters if needed */):
    # Aggregate your data by date and transaction type here
    # Create a figure and return it
    figure = go.Figure()  # Your Plotly figure logic here
    return figure

@app.callback(
    Output('category-bar-chart', 'figure'),
    # Input(...) - define any inputs for the bar chart if needed
)
def update_category_bar_chart(/* parameters if needed */):
    # Aggregate your data for category spend here
    # Create a figure and return it
    figure = go.Figure()  # Your Plotly figure logic here
    return figure

# Define similar callbacks for other components as needed...

if __name__ == '__main__':
    app.run_server(debug=True)









=IF(AND(B2=1, G2=1), "1", "0") & IF(AND(C2=1, H2=1), "1", "0") & IF(AND(D2=1, I2=1), "1", "0") & IF(AND(E2=1, J2=1), "1", "0") & IF(AND(F2=1, K2=1), "1", "0")
=IF(B2=G2, "1", "0") & IF(C2=H2, "1", "0") & IF(D2=I2, "1", "0") & IF(E2=J2, "1", "0") & IF(F2=K2, "1", "0")

=IF(OR((B2=G2)*(B2<>""), (C2=H2)*(C2<>""), (D2=I2)*(D2<>""), (E2=J2)*(E2<>""), (F2=K2)*(F2<>"")), 1, 0)








CREATE OR REPLACE TEMP TABLE AMBS_BASE1 AS
WITH Preprocessed AS (
  SELECT
    *,
    CASE
      WHEN TRIM(BLOCK_CODE_1) = '' THEN NULL
      ELSE DATE_BLOCK_CODE_1
    END AS DATE_BLOCK_CODE_1_new,
    CASE
      WHEN TRIM(BLOCK_CODE_2) = '' THEN NULL
      ELSE DATE_BLOCK_CODE_2
    END AS DATE_BLOCK_CODE_2_new
  FROM
    `project.dataset.AMBS_BASE` -- Adjust this to your actual project and dataset
)

SELECT
  *,
  LEAST(
    COALESCE(DATE_BLOCK_CODE_1_new, DATE_BLOCK_CODE_2_new),
    COALESCE(DATE_BLOCK_CODE_2_new, DATE_BLOCK_CODE_1_new)
  ) AS FIRST_BLOCK_DATE,
  CASE
    WHEN DATE_BLOCK_CODE_1_new IS NOT NULL THEN DATE_BLOCK_CODE_1_new
    ELSE DATE_BLOCK_CODE_2_new
  END AS PRIORITY_BLOCK_DATE,
  CASE
    WHEN REGEXP_REPLACE(BLOCK_CODE_1, r'\\s+', '') IN ('', 'A', 'B', 'C', 'D', 'E')
         AND REGEXP_REPLACE(BLOCK_CODE_2, r'\\s+', '') IN ('', 'A', 'B', 'C', 'D', 'E')
         AND REGEXP_REPLACE(int_Status, r'\\s+', '') IN ('A', 'D') THEN 1
    ELSE 0
  END AS aif_ind1,
  CASE
    WHEN int_status NOT IN ('f', 'g', 'h', 'u')
         AND (REGEXP_REPLACE(BLOCK_CODE_1, r'\\s+', '') IN ('A', 'Q', 'H') OR CURR_BAL / 100 > 0)
         AND CHGOFF_STATUS NOT IN ('5', '6') THEN 1
    ELSE 0
  END AS aif_risk1,
  CASE
    WHEN REGEXP_REPLACE(int_Status, r'\\s+', '') IN ('A', 'D') THEN 1
    ELSE 0
  END AS VAL_INT_STATUS
FROM
  Preprocessed;







CREATE OR REPLACE TEMP TABLE AMBS_BASE2 AS
SELECT 
  *,
  CASE
    WHEN LOGO = 420 THEN "CASHBACK"
    WHEN LOGO IN (410, 510, 501) THEN "GOLD"
    WHEN LOGO = 401 AND DATE_OPENED >= '2018-08-01' THEN "SVC"
    WHEN LOGO = 401 AND DATE_OPENED < '2018-08-01' THEN "GOLD"
    WHEN LOGO IN (415, 418) THEN "PLATINUM"
    WHEN LOGO = 515 THEN "PREMIER"
    ELSE "OTHER"
  END AS CARD_TYPE1
FROM AMBS_BASE1
WHERE aif_ind1 = 1;








CREATE OR REPLACE TEMP TABLE AMBS_BASE1 AS
SELECT
  *,
  -- Handle the conversion of BLOCK_CODE_X to dates; assume they're already in a compatible format or need conversion.
  CASE
    WHEN TRIM(BLOCK_CODE_1) = '' THEN NULL
    ELSE DATE_BLOCK_CODE_1
  END AS DATE_BLOCK_CODE_1_new,
  CASE
    WHEN TRIM(BLOCK_CODE_2) = '' THEN NULL
    ELSE DATE_BLOCK_CODE_2
  END AS DATE_BLOCK_CODE_2_new,
  -- Compute the FIRST_BLOCK_DATE as the minimum of the new date fields.
  LEAST(
    COALESCE(DATE_BLOCK_CODE_1_new, DATE_BLOCK_CODE_2_new),
    COALESCE(DATE_BLOCK_CODE_2_new, DATE_BLOCK_CODE_1_new)
  ) AS FIRST_BLOCK_DATE,
  -- Set PRIORITY_BLOCK_DATE based on the non-null condition of DATE_BLOCK_CODE_1_new.
  CASE
    WHEN DATE_BLOCK_CODE_1_new IS NOT NULL THEN DATE_BLOCK_CODE_1_new
    ELSE DATE_BLOCK_CODE_2_new
  END AS PRIORITY_BLOCK_DATE,
  -- Conditional logic for aif_ind1, considering compression (i.e., removing spaces and comparing).
  CASE
    WHEN REGEXP_REPLACE(BLOCK_CODE_1, r'\\s+', '') IN ('', 'A', 'B', 'C', 'D', 'E')
         AND REGEXP_REPLACE(BLOCK_CODE_2, r'\\s+', '') IN ('', 'A', 'B', 'C', 'D', 'E')
         AND REGEXP_REPLACE(int_Status, r'\\s+', '') IN ('A', 'D') THEN 1
    ELSE 0
  END AS aif_ind1,
  -- Logic for aif_risk1 with similar use of REGEXP_REPLACE to simulate SAS's compress function.
  CASE
    WHEN int_status NOT IN ('f', 'g', 'h', 'u')
         AND (REGEXP_REPLACE(BLOCK_CODE_1, r'\\s+', '') IN ('A', 'Q', 'H') OR CURR_BAL / 100 > 0)
         AND CHGOFF_STATUS NOT IN ('5', '6') THEN 1
    ELSE 0
  END AS aif_risk1,
  -- Conditional logic for VAL_INT_STATUS.
  CASE
    WHEN REGEXP_REPLACE(int_Status, r'\\s+', '') IN ('A', 'D') THEN 1
    ELSE 0
  END AS VAL_INT_STATUS
FROM
  `project.dataset.AMBS_BASE`; -- Adjust this to your project and dataset names











CREATE TEMP TABLE Temp_AMBS_BASE AS
WITH AMBS_BASE AS (
  -- Your original dataset query here. This is just a placeholder.
  SELECT * FROM `your-dataset.your-table`
)

, PREPARED_DATA AS (
  SELECT
    *,
    CASE
      WHEN BLOCK_CODE_1 IS NOT NULL AND BLOCK_CODE_1 != '' THEN DATE_BLOCK_CODE_1
      ELSE NULL
    END AS DATE_BLOCK_CODE_1_new,
    CASE
      WHEN BLOCK_CODE_2 IS NOT NULL AND BLOCK_CODE_2 != '' THEN DATE_BLOCK_CODE_2
      ELSE NULL
    END AS DATE_BLOCK_CODE_2_new,
    LEAST(COALESCE(DATE_BLOCK_CODE_1_new, DATE_BLOCK_CODE_2_new), COALESCE(DATE_BLOCK_CODE_2_new, DATE_BLOCK_CODE_1_new)) AS FIRST_BLOCK_DATE,
    CASE
      WHEN DATE_BLOCK_CODE_1_new IS NOT NULL THEN DATE_BLOCK_CODE_1_new
      ELSE DATE_BLOCK_CODE_2_new
    END AS PRIORITY_BLOCK_DATE
  FROM
    AMBS_BASE
)

SELECT
  *,
  CASE
    WHEN REGEXP_REPLACE(BLOCK_CODE_2, r'\s+', '') IN ('', 'A', 'B', 'C', 'D', 'E')
         AND REGEXP_REPLACE(int_Status, r'\s+', '') IN ('A', 'D') THEN 1
    ELSE 0
  END AS aif_ind1,
  CASE
    WHEN int_status NOT IN ('f', 'g', 'h', 'u')
         AND (REGEXP_REPLACE(BLOCK_CODE_1, r'\s+', '') IN ('A', 'Q', 'H') OR CURR_BAL/100 > 0)
         AND CHGOFF_STATUS NOT IN ('5', '6') THEN 1
    ELSE 0
  END AS aif_risk1,
  CASE
    WHEN REGEXP_REPLACE(int_Status, r'\s+', '') IN ('A', 'D') THEN 1
    ELSE 0
  END AS VAL_INT_STATUS
FROM
  PREPARED_DATA;
