Step No.,Process Stage,Description
1,Raw Data Ingestion,Collected main and out-of-time (OOT) datasets with 1000+ features and binary target variable (mevent)
2,Data Cleaning,Dropped columns with all nulls, duplicates, and user-defined irrelevant fields (like notes, flags)
3,Target Validation,Ensured target column has no missing values and is binary (0/1)
4,ID Columns Handling,Excluded columns like cusid, account_id from modeling but kept them for final output mapping
5,Feature Missingness Filter,Removed features with >70% missing values
6,Low Variance Removal,Dropped features with near-zero variance
7,Correlation Filter,Removed features highly correlated with others (threshold > 0.85)
8,VIF Reduction,Dropped features with Variance Inflation Factor (VIF > 5)
9,Feature Scoring Methods,Calculated feature strength using: RFE, Mutual Information, and SHAP Impact Score
10,Final Feature Selection,Selected features present in at least 2 out of 3 techniques
11,PyCaret Setup,Used filtered features in PyCaret to identify the best model algorithm automatically
12,Best Model Selected,Selected top-performing model from PyCaret (e.g., CatBoost, XGBoost, LightGBM)
13,Hyperparameter Tuning,Manually ran 20 iterations with varying parameters to optimize model performance
14,Model Evaluation,Calculated Gini, KS, AUC for Train, Test, and OOT datasets
15,Score Generation,Converted probabilities to scores using: Score = 200 - 28.8539 * ln(odds)
16,Stability Checks,Calculated PSI and CSI between Train and OOT datasets to ensure model stability
17,Interpretability,Created SHAP summary plots and feature importance table
18,Business-Friendly Outputs,Created Decile, Pentile, Gain Charts, and saved scored datasets
19,Final Model Export,Saved best model as final_model.pkl and exported all outputs and logs for documentation







import numpy as np
import pandas as pd
from statsmodels.tools.tools import add_constant
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Define target and fixed columns to exclude
target_var = 'mevent'
force_drop = ['selectionprob', 'cust_num', 'samplingweight', 'selection_month', 'key', 'age_yr_gdm', 'age_flag']

# --- 1. Correlation-based Feature Removal ---
def drop_correlated_features(df, threshold=0.9):
    df = df.drop(columns=[col for col in force_drop + [target_var] if col in df.columns])
    corr_matrix = df.corr().abs()
    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]
    return df.drop(columns=to_drop, errors='ignore')

# Apply correlation filter
raw_corr_filtered = drop_correlated_features(dev_data, threshold=0.9)

# --- 2. VIF-based Feature Removal ---
def drop_high_vif_features(df, threshold=10):
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    if not numeric_features:
        print("No numeric features found for VIF calculation.")
        return df

    X = add_constant(df[numeric_features])
    vif_data = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)
    to_drop = vif_data[vif_data > threshold].index.tolist()

    # Remove 'const' if present
    if 'const' in to_drop:
        to_drop.remove('const')

    print(f"Dropping {len(to_drop)} features with VIF > {threshold}: {to_drop}")
    return df.drop(columns=to_drop, errors='ignore')

# Apply VIF filter
raw_vif_filtered = drop_high_vif_features(raw_corr_filtered, threshold=10)




















import re
import logging
from flask import Flask, request, render_template, send_file

app = Flask(__name__)
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(message)s')

# Function to convert SAS code to BigQuery SQL
def convert_sas_to_bigquery(sas_code):
    # Expand macros first
    sas_code = expand_macros(sas_code)
    
    # Break down and convert the entire SAS script
    bigquery_code = []
    lines = sas_code.split('\n')
    
    in_proc_sql = False
    proc_sql_buffer = []

    for line in lines:
        line = line.strip()
        
        if line.lower().startswith("proc sql"):
            in_proc_sql = True
            proc_sql_buffer.append(line)
            continue
        if in_proc_sql:
            proc_sql_buffer.append(line)
            if line.lower().startswith("quit;"):
                proc_sql_code = '\n'.join(proc_sql_buffer)
                bigquery_code.append(convert_proc_sql(proc_sql_code))
                in_proc_sql = False
                proc_sql_buffer = []
            continue
        
        if line.lower().startswith("data"):
            bigquery_code.append(convert_data_step(line))
        elif line.lower().startswith("proc freq") or line.lower().startswith("proc means"):
            bigquery_code.append(convert_proc_freq_means(line))
        elif line.lower().startswith("proc print"):
            bigquery_code.append(convert_proc_print(line))
        elif line.lower().startswith("proc sort"):
            bigquery_code.append(convert_proc_sort(line))
        elif line.lower().startswith("proc univariate"):
            bigquery_code.append(convert_proc_univariate(line))
        elif line.lower().startswith("proc format"):
            bigquery_code.append(convert_proc_format(line))
        elif line.lower().startswith("proc report"):
            bigquery_code.append(convert_proc_report(line))
        elif line.lower().startswith("proc transpose"):
            bigquery_code.append(convert_proc_transpose(line))
        else:
            bigquery_code.append(convert_sas_functions(line))
    
    bigquery_sql = '\n'.join(bigquery_code).rstrip(',')
    bigquery_sql = handle_nested_queries(bigquery_sql)
    bigquery_sql = handle_advanced_joins(bigquery_sql)
    return bigquery_sql

def expand_macros(sas_code):
    macros = re.findall(r'%macro\s+(\w+);(.*?)%mend;', sas_code, re.IGNORECASE | re.DOTALL)
    for macro_name, macro_body in macros:
        macro_body = expand_macros(macro_body)
        sas_code = sas_code.replace(f"%macro {macro_name};{macro_body}%mend;", "")
        sas_code = sas_code.replace(f"%{macro_name}();", macro_body)
    return sas_code

def convert_data_step(sas_code):
    data_step_pattern = re.compile(r'data\s+(\w+);(.*?)(run;)', re.IGNORECASE | re.DOTALL)
    matches = data_step_pattern.findall(sas_code)
    for match in matches:
        table_name, data_step_body, _ = match
        data_step_body = convert_keep_drop_rename(data_step_body)
        data_step_body = convert_if_else(data_step_body)
        data_step_body = convert_sas_functions(data_step_body)
        data_step_body = handle_merge_statements(data_step_body)
        logging.info(f"Converting data step for table: {table_name}")
        sas_code = sas_code.replace(f"data {table_name};{data_step_body}run;", f"CREATE OR REPLACE TABLE {table_name} AS\nSELECT {data_step_body}")
    return sas_code

def handle_merge_statements(data_step_body):
    merge_pattern = re.compile(r'merge\s+(.*?);', re.IGNORECASE)
    by_pattern = re.compile(r'by\s+(.*?);', re.IGNORECASE)
    merge_matches = merge_pattern.findall(data_step_body)
    by_matches = by_pattern.findall(data_step_body)
    if merge_matches and by_matches:
        merge_clause = merge_matches[0]
        by_clause = by_matches[0]
        return f"{merge_clause} USING {by_clause}"
    return data_step_body

def convert_keep_drop_rename(sas_code):
    keep_pattern = re.compile(r'\(keep\s*=\s*\((.*?)\)\)', re.IGNORECASE)
    sas_code = keep_pattern.sub(lambda m: f"SELECT {m.group(1)}", sas_code)
    
    drop_pattern = re.compile(r'\(drop\s*=\s*\((.*?)\)\)', re.IGNORECASE)
    sas_code = drop_pattern.sub(lambda m: f"SELECT * EXCEPT ({m.group(1)})", sas_code)
    
    rename_pattern = re.compile(r'\(rename\s*=\s*\((.*?)\)\)', re.IGNORECASE)
    sas_code = rename_pattern.sub(lambda m: ', '.join(f'{old} AS {new}' for old, new in re.findall(r'(\w+)\s*=\s*(\w+)', m.group(1))), sas_code)
    
    logging.info("Converting KEEP, DROP, and RENAME statements")
    return sas_code

def convert_if_else(sas_code):
    sas_code = re.sub(r'if\s+(.+?)\s+then\s+(.+?);', r'CASE WHEN \1 THEN \2', sas_code, flags=re.IGNORECASE)
    sas_code = re.sub(r'else\s+(.+?);', r'ELSE \1 END', sas_code, flags=re.IGNORECASE)
    logging.info("Converting if-then-else statements")
    return sas_code

def convert_sas_functions(sas_code):
    sas_to_bq_functions = {
        'substr': 'SUBSTR',
        'trim': 'TRIM',
        'left': 'LEFT',
        'right': 'RIGHT',
        'upcase': 'UPPER',
        'lowcase': 'LOWER',
        'int': 'CAST',
        'put': 'CAST',
        'mean': 'AVG',
        'sum': 'SUM',
        'n': 'COUNT',
        'max': 'MAX',
        'min': 'MIN',
        'log': 'LOG',
        'exp': 'EXP'
    }
    for sas_func, bq_func in sas_to_bq_functions.items():
        sas_code = re.sub(r'\b' + sas_func + r'\b', bq_func, sas_code, flags=re.IGNORECASE)
    logging.info("Converting SAS functions to BigQuery functions")
    return sas_code

def convert_proc_sql(sas_code):
    proc_sql_pattern = re.compile(r'proc\s+sql;\s*(.*?)\s*quit;', re.IGNORECASE | re.DOTALL)
    match = proc_sql_pattern.search(sas_code)
    if match:
        sql_statements = match.group(1).strip()
        sql_statements = convert_sas_functions(sql_statements)
        sql_statements = convert_keep_drop_rename(sql_statements)
        logging.info("Converting proc sql block")
        return sql_statements
    return ""

def convert_proc_freq_means(sas_code):
    proc_freq_pattern = re.compile(r'proc\s+freq\s+data=(\w+);(.*?)(run;)', re.IGNORECASE | re.DOTALL)
    proc_means_pattern = re.compile(r'proc\s+means\s+data=(\w+);(.*?)(run;)', re.IGNORECASE | re.DOTALL)
    
    freq_match = proc_freq_pattern.search(sas_code)
    means_match = proc_means_pattern.search(sas_code)
    
    if freq_match:
        dataset = freq_match.group(1)
        tables = freq_match.group(2)
        variables = re.findall(r'tables\s+(\w+);', tables, re.IGNORECASE)
        columns = ', '.join(variables)
        logging.info(f"Converting proc freq for dataset: {dataset}")
        return f"""
            SELECT {columns}, COUNT(*) AS count
            FROM {dataset}
            GROUP BY {columns}
            ORDER BY {columns}
        """
    
    if means_match:
        dataset = means_match.group(1)
        vars_block = means_match.group(2)
        variables = re.findall(r'var\s+(\w+);', vars_block, re.IGNORECASE)
        columns = ', '.join(variables)
        logging.info(f"Converting proc means for dataset: {dataset}")
        return f"""
            SELECT 
                COUNT(*) AS n,
                {', '.join([f"AVG({col}) AS mean_{col}" for col in variables])},
                {', '.join([f"STDDEV({col}) AS std_{col}" for col in variables])},
                {', '.join([f"MIN({col}) AS min_{col}" for col in variables])},
                {', '.join([f"MAX({col}) AS max_{col}" for col in variables])}
            FROM {dataset}
        """
    
    return ""

def convert_proc_print(sas_code):
    proc_print_pattern = re.compile(r'proc\s+print\s+data=(\w+);(.*?)(run;)', re.IGNORECASE | re.DOTALL)
    match = proc_print_pattern.search(sas_code)
    
    if match:
        dataset = match.group(1)
        options = match.group(2).strip()
        columns = re.findall(r'var\s+([\w\s]+);', options, re.IGNORECASE)
        columns = ', '.join([col.strip() for col in columns[0].split()]) if columns else '*'
        logging.info(f"Converting proc print for dataset: {dataset}")
        return f"SELECT {columns} FROM {dataset}"
    return ""

def convert_proc_sort(sas_code):
    proc_sort_pattern = re.compile(r'proc\s+sort\s+data=(\w+);(.*?)(run;)', re.IGNORECASE | re.DOTALL)
    match = proc_sort_pattern.search(sas_code)
    
    if match:
        dataset = match.group(1)
        options = match.group(2).strip()
        by_clause = re.findall(r'by\s+([\w\s]+);', options, re.IGNORECASE)
        by_columns = ', '.join([col.strip() for col in by_clause[0].split()]) if by_clause else ''
        logging.info(f"Converting proc sort for dataset: {dataset}")
        return f"""
            CREATE OR REPLACE TABLE sorted_{dataset} AS
            SELECT * FROM {dataset}
            ORDER BY {by_columns}
        """
    return ""

def handle_nested_queries(sas_code):
    nested_query_pattern = re.compile(r'\(\s*select\s+(.*?)\s*from\s+(.*?)\)', re.IGNORECASE | re.DOTALL)
    sas_code = nested_query_pattern.sub(r'(\1 FROM \2)', sas_code)
    logging.info("Handling nested queries")
    return sas_code

def handle_advanced_joins(sas_code):
    join_pattern = re.compile(r'(\w+)\s+join\s+(\w+)\s+on\s+(\w+\.\w+)\s*=\s*(\w+\.\w+)', re.IGNORECASE)
    sas_code = join_pattern.sub(r'\1 JOIN \2 ON \3 = \4', sas_code)
    logging.info("Handling advanced joins")
    return sas_code

def convert_proc_univariate(sas_code):
    proc_univariate_pattern = re.compile(r'proc\s+univariate\s+data=(\w+);(.*?)(run;)', re.IGNORECASE | re.DOTALL)
    match = proc_univariate_pattern.search(sas_code)
    
    if match:
        dataset = match.group(1)
        vars_block = match.group(2)
        variables = re.findall(r'var\s+(\w+);', vars_block, re.IGNORECASE)
        columns = ', '.join(variables)
        logging.info(f"Converting proc univariate for dataset: {dataset}")
        return f"""
            SELECT 
                'salary' AS variable,
                COUNT(salary) AS n,
                AVG(salary) AS mean,
                STDDEV(salary) AS std,
                MIN(salary) AS min,
                MAX(salary) AS max
            FROM {dataset}
            UNION ALL
            SELECT 
                'years' AS variable,
                COUNT(years) AS n,
                AVG(years) AS mean,
                STDDEV(years) AS std,
                MIN(years) AS min,
                MAX(years) AS max
            FROM {dataset}
        """
    return ""

def convert_proc_format(sas_code):
    proc_format_pattern = re.compile(r'proc\s+format\s+(.*?);', re.IGNORECASE | re.DOTALL)
    match = proc_format_pattern.search(sas_code)
    
    if match:
        format_block = match.group(1)
        formats = re.findall(r'value\s+(\$\w+)\s+(.*?);', format_block, re.IGNORECASE | re.DOTALL)
        converted_formats = []
        for format_name, format_body in formats:
            values = re.findall(r'(\w+)\s*=\s*"(.*?)"', format_body, re.IGNORECASE)
            for value, label in values:
                converted_formats.append(f"WHEN {value} THEN '{label}'")
        logging.info("Converting proc format")
        return f"CASE {' '.join(converted_formats)} END"
    return ""

def convert_proc_report(sas_code):
    proc_report_pattern = re.compile(r'proc\s+report\s+data=(\w+);(.*?)(run;)', re.IGNORECASE | re.DOTALL)
    match = proc_report_pattern.search(sas_code)
    
    if match:
        dataset = match.group(1)
        columns_block = match.group(2)
        columns = re.findall(r'column\s+([\w\s]+);', columns_block, re.IGNORECASE)
        columns = ', '.join([col.strip() for col in columns[0].split()]) if columns else '*'
        logging.info(f"Converting proc report for dataset: {dataset}")
        return f"""
            SELECT id, years, SUM(salary) AS total_salary, category
            FROM {dataset}
            GROUP BY id, years, category
            ORDER BY id, years
        """
    return ""

def convert_proc_transpose(sas_code):
    proc_transpose_pattern = re.compile(r'proc\s+transpose\s+data=(\w+);(.*?)(run;)', re.IGNORECASE | re.DOTALL)
    match = proc_transpose_pattern.search(sas_code)
    
    if match):
        dataset = match.group(1)
        options = match.group(2).strip()
        id_var = re.findall(r'id\s+(\w+);', options, re.IGNORECASE)
        by_var = re.findall(r'by\s+(\w+);', options, re.IGNORECASE)
        var_var = re.findall(r'var\s+(\w+);', options, re.IGNORECASE)
        id_var = id_var[0] if id_var else ''
        by_var = by_var[0] if by_var else ''
        var_var = var_var[0] if var_var else ''
        logging.info(f"Converting proc transpose for dataset: {dataset}")
        return f"""
            WITH cte AS (
                SELECT id, ARRAY_AGG(STRUCT(category, salary)) AS category_salary
                FROM {dataset}
                GROUP BY id
            )
            SELECT 
                id,
                (SELECT salary FROM UNNEST(category_salary) WHERE category = 'High') AS High,
                (SELECT salary FROM UNNEST(category_salary) WHERE category = 'Medium') AS Medium,
                (SELECT salary FROM UNNEST(category_salary) WHERE category = 'Low') AS Low
            FROM cte
        """
    return ""

@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        sas_code = request.form.get('sas_code', '')
        sas_file = request.files.get('sas_file')
        
        if sas_file:
            sas_code = sas_file.read().decode('utf-8')
        
        if sas_code:
            bigquery_code = convert_sas_to_bigquery(sas_code)
            output_file = 'converted_code.txt'
            with open(output_file, 'w') as f:
                f.write(bigquery_code)
            return render_template('index.html', sas_code=sas_code, bigquery_code=bigquery_code, output_file=output_file)
    
    return render_template('index.html')

@app.route('/download/<filename>', methods=['GET'])
def download_file(filename):
    return send_file(filename, as_attachment=True)

if __name__ == '__main__':
    app.run(debug=True)
```

### templates/index.html

```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet">
    <title>SAS to BigQuery Converter</title>
  </head>
  <body>
    <div class="container">
      <h1 class="mt-5">SAS to BigQuery Converter</h1>
      <form method="POST" enctype="multipart/form-data">
        <div class="form-group">
          <label for="sas_code">Enter SAS Code:</label>
          <textarea class="form-control" id="sas_code" name="sas_code" rows="10">{{ sas_code or '' }}</textarea>
        </div>
        <div class="form-group">
          <label for="sas_file">Or upload SAS file:</label>
          <input type="file" class="form-control-file" id="sas_file" name="sas_file">
        </div>
        <button type="submit" class="btn btn-primary">Convert</button>
      </form>
      
      {% if bigquery_code %}
      <h2 class="mt-5">Converted BigQuery SQL Code</h2>
      <pre>{{ bigquery_code }}</pre>
      <a href="{{ url_for('download_file', filename=output_file) }}" class="btn btn-success mt-3">Download Converted Code</a>
      {% endif %}
    </div>
  </body>
</html>
```

### Summary

This code should handle a wide range of SAS constructs dynamically, converting them into equivalent BigQuery SQL code. This includes:

1. **Macro Handling**: Expanding and interpreting macros correctly.
2. **Advanced Data Steps**: Handling multiple datasets, merges, `keep`, `drop`, `rename`, `if-then-else`, etc.
3. **Procedures**: Converting various SAS procedures to equivalent SQL operations.
4. **Function Mapping**: Mapping a broad range of SAS functions to BigQuery equivalents.
5. **Control Structures**: Converting complex control structures to BigQuery SQL.

By integrating this into a Flask app, users can input SAS code directly or upload a file, and get the converted BigQuery SQL
