Auc, charts

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score

# Function to create Gain Matrix with full event distribution analysis
def create_gain_matrix(model, X, y, dataset_name):
    # Get predicted probabilities
    y_pred_proba = model.predict_proba(X)[:, 1]  

    # Create DataFrame with Actual vs Predicted Probabilities
    df = pd.DataFrame({"Actual": y, "Predicted_Prob": y_pred_proba})
    
    # Create Deciles (10 bins based on predicted probability)
    df["Decile"] = pd.qcut(df["Predicted_Prob"], 10, labels=False, duplicates="drop")
    
    # Sort deciles from highest probability to lowest (Decile 1 = Highest Risk)
    df["Decile"] = 10 - df["Decile"]  

    # Compute Gain Matrix Metrics
    gain_matrix = df.groupby("Decile").agg(
        Total_Customers=("Actual", "count"),
        Events=("Actual", "sum")  # Count of positive class (event)
    ).reset_index()

    # Compute Non-Events
    gain_matrix["Non-Events"] = gain_matrix["Total_Customers"] - gain_matrix["Events"]
    
    # Cumulative Sums
    gain_matrix["Cumulative_Non_Events"] = gain_matrix["Non-Events"].cumsum()
    gain_matrix["Cumulative_Events"] = gain_matrix["Events"].cumsum()

    # Compute Percent Cumulative Events & Non-Events
    total_events = gain_matrix["Events"].sum()
    total_non_events = gain_matrix["Non-Events"].sum()

    gain_matrix["% Cumulative Non-Events"] = (gain_matrix["Cumulative_Non_Events"] / total_non_events) * 100
    gain_matrix["% Cumulative Events"] = (gain_matrix["Cumulative_Events"] / total_events) * 100

    # Compute Event Rate per Decile
    gain_matrix["Event Rate"] = gain_matrix["Events"] / gain_matrix["Total_Customers"]

    # Compute Cumulative Event Rate
    gain_matrix["Cumulative Event Rate"] = gain_matrix["Cumulative_Events"] / gain_matrix["Total_Customers"].sum()

    # Compute Separation (Difference in % Cumulative Events and Non-Events)
    gain_matrix["Separation"] = gain_matrix["% Cumulative Events"] - gain_matrix["% Cumulative Non-Events"]

    # Compute Lift (Cumulative Event Rate vs. Overall Event Rate)
    overall_event_rate = total_events / (total_events + total_non_events)
    gain_matrix["Lift"] = gain_matrix["Cumulative Event Rate"] / overall_event_rate

    # Add Dataset Name
    gain_matrix["Dataset"] = dataset_name

    return gain_matrix

# Function to calculate AUC
def calculate_auc(model, X, y):
    y_pred_proba = model.predict_proba(X)[:, 1]
    return roc_auc_score(y, y_pred_proba)

# Compute Gain Matrices
train_gain_matrix = create_gain_matrix(final_model, X_train, y_train, "Train")
test_gain_matrix = create_gain_matrix(final_model, X_test, y_test, "Test")
oot_gain_matrix = create_gain_matrix(final_model, X_oot_features, y_oot, "OOT")

# Compute AUC Scores
train_auc = calculate_auc(final_model, X_train, y_train)
test_auc = calculate_auc(final_model, X_test, y_test)
oot_auc = calculate_auc(final_model, X_oot_features, y_oot)

# Combine Gain Matrices for Display
gain_matrix_df = pd.concat([train_gain_matrix, test_gain_matrix, oot_gain_matrix])

# Display Gain Matrix Table
print("\n--- Gain Matrix (Decile Analysis) ---")
print(gain_matrix_df.to_string(index=False))

# Display AUC Scores
auc_scores_df = pd.DataFrame({
    "Dataset": ["Train", "Test", "OOT"],
    "AUC Score": [train_auc, test_auc, oot_auc]
})

print("\n--- AUC Scores ---")
print(auc_scores_df.to_string(index=False))

# Plot Cumulative Gain Chart
plt.figure(figsize=(8, 6))
plt.plot(train_gain_matrix["Decile"], train_gain_matrix["% Cumulative Events"], marker='o', label="Train")
plt.plot(test_gain_matrix["Decile"], test_gain_matrix["% Cumulative Events"], marker='s', label="Test")
plt.plot(oot_gain_matrix["Decile"], oot_gain_matrix["% Cumulative Events"], marker='^', label="OOT")

plt.xlabel("Decile (1 = Highest Risk)")
plt.ylabel("Cumulative % of Events")
plt.title("Cumulative Gain Chart Based on Deciles")
plt.legend()
plt.grid(True)
plt.show()

# Plot Lift Chart
plt.figure(figsize=(8, 6))
plt.plot(train_gain_matrix["Decile"], train_gain_matrix["Lift"], marker='o', label="Train")
plt.plot(test_gain_matrix["Decile"], test_gain_matrix["Lift"], marker='s', label="Test")
plt.plot(oot_gain_matrix["Decile"], oot_gain_matrix["Lift"], marker='^', label="OOT")

plt.xlabel("Decile (1 = Highest Risk)")
plt.ylabel("Lift")
plt.title("Lift Chart Based on Deciles")
plt.legend()
plt.grid(True)
plt.show()















Main Model

import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import roc_auc_score
import joblib

# Load Data (Ensure `Dev_data1` and `X_oot` are preloaded as DataFrames)
target_column = "mevent"  # Update with actual target variable name
ignore_features = ["cust_num", "samplingweight", "selection_time"]  # Features to ignore

# Remove ignored features from model input, but keep them in the dataset
X = Dev_data1.drop(columns=[target_column] + ignore_features)
y = Dev_data1[target_column]

# Ensure consistent Train-Test Split using random_state=1992
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1992)

# Prepare OOT dataset (Ensure features match Train/Test datasets)
y_oot = X_oot[target_column]
X_oot_features = X_oot.drop(columns=[target_column] + ignore_features)
X_oot_features = X_oot_features[X_train.columns]  # Ensure feature consistency

# Function to calculate Gini Score
def calculate_gini(model, X, y):
    y_pred = model.predict_proba(X)[:, 1]  # Get probabilities
    auc = roc_auc_score(y, y_pred)
    gini = 2 * auc - 1  # Convert AUC to Gini
    return gini

# Function to generate Scores and Odds
def generate_scores_odds(model, X):
    probs = model.predict_proba(X)[:, 1]  # Get probability of class 1
    scores = np.log(probs / (1 - probs))  # Log odds transformation
    return pd.DataFrame({"Score": scores, "Odds": probs / (1 - probs)})

# Define Hyperparameter Search Space (20 Iterations)
param_grid = {
    "learning_rate": np.linspace(0.01, 0.3, 10),
    "max_depth": np.arange(3, 10),
    "min_samples_leaf": np.arange(1, 50, 5),
    "n_estimators": np.arange(100, 1000, 100),
    "subsample": np.linspace(0.5, 1.0, 5)
}

# Gradient Boosting Classifier with fixed random_state
gb_model = GradientBoostingClassifier(random_state=1992)

# Use RandomizedSearchCV for Hyperparameter Tuning (20 Iterations) with fixed random_state
random_search = RandomizedSearchCV(
    estimator=gb_model,
    param_distributions=param_grid,
    n_iter=20,  # 20 Iterations
    scoring="roc_auc",
    cv=5,
    random_state=1992,  # Fixed random state for consistency
    verbose=1,
    n_jobs=-1
)

# Fit the Model
random_search.fit(X_train, y_train)

# Store Results for Each Iteration
results = []
for i, params in enumerate(random_search.cv_results_["params"]):
    best_model = GradientBoostingClassifier(**params, random_state=1992)  # Ensure consistent model training
    best_model.fit(X_train, y_train)

    # Compute Gini Scores
    train_gini = calculate_gini(best_model, X_train, y_train)
    test_gini = calculate_gini(best_model, X_test, y_test)
    oot_gini = calculate_gini(best_model, X_oot_features, y_oot)

    # Store iteration results
    results.append({
        "Iteration": i + 1,
        "Learning Rate": params.get("learning_rate"),
        "Max Depth": params.get("max_depth"),
        "Min Samples Leaf": params.get("min_samples_leaf"),
        "Estimators": params.get("n_estimators"),
        "Subsample": params.get("subsample"),
        "Train Gini": train_gini,
        "Test Gini": test_gini,
        "OOT Gini": oot_gini,
        "Train-OOT Gini Diff": abs(train_gini - oot_gini)
    })

# Convert results into DataFrame
results_df = pd.DataFrame(results)

# Step 5: Select Best Model (Highest Test Gini, Smallest Train-OOT Gini Difference)
best_model_row = results_df[results_df["Train-OOT Gini Diff"] < 0.05].nlargest(1, "Test Gini")

# Step 6: Train & Save the Best Model
best_params = best_model_row.iloc[0][["Learning Rate", "Max Depth", "Min Samples Leaf", "Estimators", "Subsample"]].to_dict()
final_model = GradientBoostingClassifier(
    learning_rate=best_params["Learning Rate"],
    max_depth=int(best_params["Max Depth"]),
    min_samples_leaf=int(best_params["Min Samples Leaf"]),
    n_estimators=int(best_params["Estimators"]),
    subsample=best_params["Subsample"],
    random_state=1992  # Keep the same random state
)

final_model.fit(X_train, y_train)
joblib.dump(final_model, "best_gradient_boosting.pkl")  # Save Model

# Generate Scores & Odds for all datasets
dev_scores = generate_scores_odds(final_model, X)
train_scores = generate_scores_odds(final_model, X_train)
test_scores = generate_scores_odds(final_model, X_test)
oot_scores = generate_scores_odds(final_model, X_oot_features)

# Step 7: Display Results Table
import ace_tools as tools
tools.display_dataframe_to_user(name="Gradient Boosting Hyperparameter Tuning Results", dataframe=results_df)
tools.display_dataframe_to_user(name="Dev Data Scores & Odds", dataframe=dev_scores)
tools.display_dataframe_to_user(name="Train Data Scores & Odds", dataframe=train_scores)
tools.display_dataframe_to_user(name="Test Data Scores & Odds", dataframe=test_scores)
tools.display_dataframe_to_user(name="OOT Data Scores & Odds", dataframe=oot_scores)