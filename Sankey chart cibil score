import pandas as pd
import plotly.graph_objects as go
import random

# Sample data setup
data = {
    'cusid': range(1, 11),
    'nov-bucket': ['600-650', '650-700', '700-750', '750-800', '600-650', '700-750', '700-750', '750-800', '800-850', '850-900'],
    'jan-bucket': ['600-650', '650-700', '700-750', '750-800', '650-700', '700-750', '700-750', '750-800', '850-900', '850-900'],
    'feb-bucket': ['600-650', '700-750', '700-750', '800-850', '700-750', '700-750', '700-750', '850-900', '<600', '850-900'],
    'apr-bucket': ['600-650', '800-850', '700-750', '<600', '750-800', '700-750', '700-750', '<600', '600-650', '650-700']
}

df = pd.DataFrame(data)

# Adjust the bucket labels to include the month for uniqueness
months = ['nov', 'jan', 'feb', 'apr']
for month in months:
    df[f'{month}-bucket'] = df[f'{month}-bucket'].apply(lambda x: f"{x} ({month})")

# Define the desired order of buckets
desired_order = ['850-900', '800-850', '750-800', '700-750', '650-700', '600-650', '<600', 'nan']

# Create a dictionary to map bucket labels to their order index
bucket_order = {f"{bucket} ({month})": i for i, bucket in enumerate(desired_order) for month in months}

# Prepare lists to hold source, target, values, and colors
sources = []
targets = []
values = []
labels = []
hover_text = []
link_colors = []

# Unique bucket names for mapping, keeping the order
unique_buckets = sorted(bucket_order.keys(), key=lambda x: bucket_order[x])
bucket_index = {bucket: i for i, bucket in enumerate(unique_buckets)}

# Generate a different color for each unique bucket
def random_color():
    return f'rgba({random.randint(0, 255)}, {random.randint(0, 255)}, {random.randint(0, 255)}, 0.8)'

bucket_colors = {bucket: random_color() for bucket in unique_buckets}

# Generate the source, target, value, color, and labels lists
for i in range(len(months) - 1):
    transitions = df.groupby([f'{months[i]}-bucket', f'{months[i+1]}-bucket']).size().reset_index(name='count')
    source_totals = transitions.groupby(f'{months[i]}-bucket')['count'].sum().to_dict()
    for _, row in transitions.iterrows():
        sources.append(bucket_index[row[f'{months[i]}-bucket']])
        targets.append(bucket_index[row[f'{months[i+1]}-bucket']])
        values.append(row['count'])

        # Calculate the percentage change within each source bucket
        source_total = source_totals[row[f'{months[i]}-bucket']]
        percentage = (row['count'] / source_total) * 100
        labels.append(f"{row[f'{months[i]}-bucket']} → {row[f'{months[i+1]}-bucket']} ({percentage:.2f}%)")
        
        # Detailed hover information
        hover_text.append(f"<b>Transition:</b> {row[f'{months[i]}-bucket']} to {row[f'{months[i+1]}-bucket']}<br>"
                          f"<b>Count:</b> {row['count']}<br>"
                          f"<b>Percentage:</b> {percentage:.2f}%")

        link_colors.append(bucket_colors[row[f'{months[i]}-bucket']])  # Use the color of the source bucket

# Create the Sankey diagram
fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=20,
        thickness=30,
        line=dict(color="black", width=0.7),
        label=unique_buckets,
        color=[bucket_colors[bucket] for bucket in unique_buckets]  # Assign colors to nodes
    ),
    link=dict(
        source=sources,
        target=targets,
        value=values,
        color=link_colors,
        customdata=hover_text,
        hovertemplate='%{customdata}<extra></extra>'
    ))])

# Add bar chart traces for each node
for bucket in unique_buckets:
    counts = df.apply(lambda row: (row == bucket).sum(), axis=1).value_counts()
    fig.add_trace(go.Bar(
        x=counts.index,
        y=counts.values,
        name=bucket,
        visible=False
    ))

# Create update menus to toggle the visibility of bar charts
buttons = []
for i, bucket in enumerate(unique_buckets):
    button = dict(
        label=bucket,
        method='update',
        args=[{'visible': [False] * len(fig.data)},
              {'title': f"Distribution of Customers in {bucket}"}]
    )
    button['args'][0]['visible'][0] = True  # Always show the Sankey diagram
    button['args'][0]['visible'][i + 1] = True  # Show the corresponding bar chart
    buttons.append(button)

updatemenus = [dict(active=-1, buttons=buttons, direction='down', showactive=True)]

fig.update_layout(
    title_text="Customer Movements Across CIBIL Score Buckets Over Months",
    font_size=12,
    plot_bgcolor='white',
    paper_bgcolor='white',
    updatemenus=updatemenus
)

fig.show()












import pandas as pd
import plotly.graph_objects as go
import random

# Sample data setup
data = {
    'cusid': range(1, 11),
    'nov-bucket': ['600-650', '650-700', '700-750', '750-800', '600-650', '700-750', '700-750', '750-800', '800-850', '850-900'],
    'jan-bucket': ['600-650', '650-700', '700-750', '750-800', '650-700', '700-750', '700-750', '750-800', '850-900', '850-900'],
    'feb-bucket': ['600-650', '700-750', '700-750', '800-850', '700-750', '700-750', '700-750', '850-900', '<600', '850-900'],
    'apr-bucket': ['600-650', '800-850', '700-750', '<600', '750-800', '700-750', '700-750', '<600', '600-650', '650-700']
}

df = pd.DataFrame(data)

# Adjust the bucket labels to include the month for uniqueness
months = ['nov', 'jan', 'feb', 'apr']
for month in months:
    df[f'{month}-bucket'] = df[f'{month}-bucket'].apply(lambda x: f"{x} ({month})")

# Define the desired order of buckets
desired_order = ['850-900', '800-850', '750-800', '700-750', '650-700', '600-650', '<600', 'nan']

# Create a dictionary to map bucket labels to their order index
bucket_order = {f"{bucket} ({month})": i for i, bucket in enumerate(desired_order) for month in months}

# Prepare lists to hold source, target, values, and colors
sources = []
targets = []
values = []
labels = []
hover_text = []
link_colors = []

# Unique bucket names for mapping, keeping the order
unique_buckets = sorted(bucket_order, key=bucket_order.get)
bucket_index = {bucket: i for i, bucket in enumerate(unique_buckets)}

# Generate a different color for each unique bucket
def random_color():
    return f'rgba({random.randint(0, 255)}, {random.randint(0, 255)}, {random.randint(0, 255)}, 0.8)'

bucket_colors = {bucket: random_color() for bucket in unique_buckets}

# Generate the source, target, value, color, and labels lists
for i in range(len(months) - 1):
    transitions = df.groupby([f'{months[i]}-bucket', f'{months[i+1]}-bucket']).size().reset_index(name='count')
    source_totals = transitions.groupby(f'{months[i]}-bucket')['count'].sum().to_dict()
    for _, row in transitions.iterrows():
        sources.append(bucket_index[row[f'{months[i]}-bucket']])
        targets.append(bucket_index[row[f'{months[i+1]}-bucket']])
        values.append(row['count'])

        # Calculate the percentage change within each source bucket
        source_total = source_totals[row[f'{months[i]}-bucket']]
        percentage = (row['count'] / source_total) * 100
        labels.append(f"{row[f'{months[i]}-bucket']} → {row[f'{months[i+1]}-bucket']} ({percentage:.2f}%)")
        
        # Detailed hover information
        hover_text.append(f"<b>Transition:</b> {row[f'{months[i]}-bucket']} to {row[f'{months[i+1]}-bucket']}<br>"
                          f"<b>Count:</b> {row['count']}<br>"
                          f"<b>Percentage:</b> {percentage:.2f}%")

        link_colors.append(bucket_colors[row[f'{months[i]}-bucket']])  # Use the color of the source bucket

# Create the Sankey diagram
fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=20,
        thickness=30,
        line=dict(color="black", width=0.7),
        label=unique_buckets,
        color=[bucket_colors[bucket] for bucket in unique_buckets]  # Assign colors to nodes
    ),
    link=dict(
        source=sources,
        target=targets,
        value=values,
        color=link_colors,
        customdata=hover_text,
        hovertemplate='%{customdata}<extra></extra>'
    ))])

fig.update_layout(
    title_text="Customer Movements Across CIBIL Score Buckets Over Months",
    font_size=12,
    plot_bgcolor='white',
    paper_bgcolor='white'
)

fig.show()











import pandas as pd
import plotly.graph_objects as go
import random

# Sample data setup
data = {
    'cusid': range(1, 11),
    'nov-bucket': ['600-650', '650-700', '700-750', '750-800', '600-650', '700-750', '700-750', '750-800', '800-850', '850-900'],
    'jan-bucket': ['600-650', '650-700', '700-750', '750-800', '650-700', '700-750', '700-750', '750-800', '850-900', '850-900'],
    'feb-bucket': ['600-650', '700-750', '700-750', '800-850', '700-750', '700-750', '700-750', '850-900', '<600', '850-900'],
    'apr-bucket': ['600-650', '800-850', '700-750', '<600', '750-800', '700-750', '700-750', '<600', '600-650', '650-700']
}

df = pd.DataFrame(data)

# Adjust the bucket labels to include the month for uniqueness
months = ['nov', 'jan', 'feb', 'apr']
for month in months:
    df[f'{month}-bucket'] = df[f'{month}-bucket'].apply(lambda x: f"{x} ({month})")

# Define the desired order of buckets
desired_order = ['850-900', '800-850', '750-800', '700-750', '650-700', '600-650', '<600', 'nan']

# Create a dictionary to map bucket labels to their order index
bucket_order = {f"{bucket} ({month})": i for i, bucket in enumerate(desired_order) for month in months}

# Prepare lists to hold source, target, values, and colors
sources = []
targets = []
values = []
labels = []
hover_text = []
link_colors = []

# Unique bucket names for mapping, keeping the order
unique_buckets = sorted(bucket_order, key=bucket_order.get)
bucket_index = {bucket: i for i, bucket in enumerate(unique_buckets)}

# Generate a different color for each unique bucket
def random_color():
    return f'rgba({random.randint(0, 255)}, {random.randint(0, 255)}, {random.randint(0, 255)}, 0.8)'

bucket_colors = {bucket: random_color() for bucket in unique_buckets}

# Generate the source, target, value, color, and labels lists
for i in range(len(months) - 1):
    transitions = df.groupby([f'{months[i]}-bucket', f'{months[i+1]}-bucket']).size().reset_index(name='count')
    source_totals = transitions.groupby(f'{months[i]}-bucket')['count'].sum().to_dict()
    for _, row in transitions.iterrows():
        sources.append(bucket_index[row[f'{months[i]}-bucket']])
        targets.append(bucket_index[row[f'{months[i+1]}-bucket']])
        values.append(row['count'])

        # Calculate the percentage change within each source bucket
        source_total = source_totals[row[f'{months[i]}-bucket']]
        percentage = (row['count'] / source_total) * 100
        labels.append(f"{row[f'{months[i]}-bucket']} → {row[f'{months[i+1]}-bucket']} ({percentage:.2f}%)")
        
        # Detailed hover information
        hover_text.append(f"<b>Transition:</b> {row[f'{months[i]}-bucket']} to {row[f'{months[i+1]}-bucket']}<br>"
                          f"<b>Count:</b> {row['count']}<br>"
                          f"<b>Percentage:</b> {percentage:.2f}%")

        link_colors.append(bucket_colors[row[f'{months[i]}-bucket']])  # Use the color of the source bucket

# Create the Sankey diagram
fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=20,
        thickness=30,
        line=dict(color="black", width=0.7),
        label=unique_buckets,
        color=[bucket_colors[bucket] for bucket in unique_buckets]  # Assign colors to nodes
    ),
    link=dict(
        source=sources,
        target=targets,
        value=values,
        color=link_colors,
        hoverinfo="text",
        customdata=labels,
        hovertemplate='%{customdata}<extra></extra>'
    ))])

fig.update_layout(
    title_text="Customer Movements Across CIBIL Score Buckets Over Months",
    font_size=12,
    plot_bgcolor='white',
    paper_bgcolor='white'
)

fig.show()o







import pandas as pd
import plotly.graph_objects as go
import random

# Sample data setup
data = {
    'cusid': range(1, 11),
    'nov-bucket': ['600-650', '650-700', '700-750', '750-800', '600-650', '700-750', '700-750', '750-800', '800-850', '850-900'],
    'jan-bucket': ['600-650', '650-700', '700-750', '750-800', '650-700', '700-750', '700-750', '750-800', '850-900', '850-900'],
    'feb-bucket': ['600-650', '700-750', '700-750', '800-850', '700-750', '700-750', '700-750', '850-900', '<600', '850-900'],
    'apr-bucket': ['600-650', '800-850', '700-750', '<600', '750-800', '700-750', '700-750', '<600', '600-650', '650-700']
}

df = pd.DataFrame(data)

# Adjust the bucket labels to include the month for uniqueness
months = ['nov', 'jan', 'feb', 'apr']
for month in months:
    df[f'{month}-bucket'] = df[f'{month}-bucket'].apply(lambda x: f"{x} ({month})")

# Define the desired order of buckets
desired_order = ['850-900', '800-850', '750-800', '700-750', '650-700', '600-650', '<600', 'nan']

# Create a dictionary to map bucket labels to their order index
bucket_order = {f"{bucket} ({month})": i for i, bucket in enumerate(desired_order) for month in months}

# Prepare lists to hold source, target, values, and colors
sources = []
targets = []
values = []
labels = []
link_colors = []

# Unique bucket names for mapping, keeping the order
unique_buckets = sorted(bucket_order, key=bucket_order.get)
bucket_index = {bucket: i for i, bucket in enumerate(unique_buckets)}

# Generate a different color for each unique bucket
def random_color():
    return f'rgba({random.randint(0, 255)}, {random.randint(0, 255)}, {random.randint(0, 255)}, 0.5)'

bucket_colors = {bucket: random_color() for bucket in unique_buckets}

# Generate the source, target, value, color, and labels lists
for i in range(len(months) - 1):
    transitions = df.groupby([f'{months[i]}-bucket', f'{months[i+1]}-bucket']).size().reset_index(name='count')
    source_totals = transitions.groupby(f'{months[i]}-bucket')['count'].sum().to_dict()
    for _, row in transitions.iterrows():
        sources.append(bucket_index[row[f'{months[i]}-bucket']])
        targets.append(bucket_index[row[f'{months[i+1]}-bucket']])
        values.append(row['count'])

        # Calculate the percentage change within each source bucket
        source_total = source_totals[row[f'{months[i]}-bucket']]
        percentage = (row['count'] / source_total) * 100
        labels.append(f"{row[f'{months[i]}-bucket']} → {row[f'{months[i+1]}-bucket']} ({percentage:.2f}%)")
        
        link_colors.append(bucket_colors[row[f'{months[i]}-bucket']])  # Use the color of the source bucket

# Create the Sankey diagram
fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=unique_buckets,
        color=[bucket_colors[bucket] for bucket in unique_buckets]  # Assign colors to nodes
    ),
    link=dict(
        source=sources,
        target=targets,
        value=values,
        color=link_colors,
        label=labels  # Add movement percentage to the link label
    ))])

fig.update_layout(title_text="Customer Movements Across CIBIL Score Buckets Over Months", font_size=10)
fig.show()












import pandas as pd
import plotly.graph_objects as go
import random

# Sample data setup
data = {
    'cusid': range(1, 11),
    'nov-bucket': ['600-650', '650-700', '700-750', '750-800', '600-650', '700-750', '700-750', '750-800', '800-850', '850-900'],
    'jan-bucket': ['600-650', '650-700', '700-750', '750-800', '650-700', '700-750', '700-750', '750-800', '850-900', '850-900'],
    'feb-bucket': ['600-650', '700-750', '700-750', '800-850', '700-750', '700-750', '700-750', '850-900', '<600', '850-900'],
    'apr-bucket': ['600-650', '800-850', '700-750', '<600', '750-800', '700-750', '700-750', '<600', '600-650', '650-700']
}

df = pd.DataFrame(data)

# Adjust the bucket labels to include the month for uniqueness
months = ['nov', 'jan', 'feb', 'apr']
for month in months:
    df[f'{month}-bucket'] = df[f'{month}-bucket'].apply(lambda x: f"{x} ({month})")

# Prepare lists to hold source, target, values, and colors
sources = []
targets = []
values = []
labels = []
link_colors = []

# Unique bucket names for mapping
unique_buckets = set()
for col in df.columns[1:]:
    unique_buckets.update(df[col].unique())
unique_buckets = list(unique_buckets)
bucket_index = {bucket: i for i, bucket in enumerate(unique_buckets)}

# Generate a consistent color for each bucket
def random_color():
    return f'rgba({random.randint(0, 255)}, {random.randint(0, 255)}, {random.randint(0, 255)}, 0.5)'

bucket_colors = {bucket: random_color() for bucket in unique_buckets}

# Generate the source, target, value, color, and labels lists
for i in range(len(months) - 1):
    transitions = df.groupby([f'{months[i]}-bucket', f'{months[i+1]}-bucket']).size().reset_index(name='count')
    source_totals = transitions.groupby(f'{months[i]}-bucket')['count'].sum().to_dict()
    for _, row in transitions.iterrows():
        sources.append(bucket_index[row[f'{months[i]}-bucket']])
        targets.append(bucket_index[row[f'{months[i+1]}-bucket']])
        values.append(row['count'])

        # Calculate the percentage change within each source bucket
        source_total = source_totals[row[f'{months[i]}-bucket']]
        percentage = (row['count'] / source_total) * 100
        labels.append(f"{row[f'{months[i]}-bucket']} → {row[f'{months[i+1]}-bucket']} ({percentage:.2f}%)")
        
        link_colors.append(bucket_colors[row[f'{months[i]}-bucket']])  # Use the color of the source bucket

# Create the Sankey diagram
fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=unique_buckets,
        color=[bucket_colors[bucket] for bucket in unique_buckets]  # Assign colors to nodes
    ),
    link=dict(
        source=sources,
        target=targets,
        value=values,
        color=link_colors,
        label=labels  # Add movement percentage to the link label
    ))])

fig.update_layout(title_text="Customer Movements Across CIBIL Score Buckets Over Months", font_size=10)
fig.show()










import matplotlib.pyplot as plt

# Plot distribution of score buckets
bucket_counts.plot(kind='bar', figsize=(14, 8))
plt.title('Distribution of CIBIL Score Buckets by Month')
plt.xlabel('CIBIL Score Bucket')
plt.ylabel('Number of Customers')
plt.xticks(rotation=45)
plt.show()










# Distribution of buckets for each month
bucket_counts_nov = data_buckets['nov-bucket'].value_counts().sort_index()
bucket_counts_jan = data_buckets['jan-bucket'].value_counts().sort_index()
bucket_counts_feb = data_buckets['feb-bucket'].value_counts().sort_index()
bucket_counts_apr = data_buckets['apr-bucket'].value_counts().sort_index()

bucket_counts = pd.DataFrame({
    'November': bucket_counts_nov,
    'January': bucket_counts_jan,
    'February': bucket_counts_feb,
    'April': bucket_counts_apr
}).fillna(0)

bucket_counts












SELECT *
FROM your_table
WHERE your_date_column >= (current_date - (date_part('day', current_date) - 1) * interval '1 day')
AND your_date_column <= current_date;



SELECT *
FROM your_table
WHERE your_date_column >= date_trunc('month', now())
AND your_date_column < date_trunc('day', now()) + interval '1 day';





import pandas as pd
import matplotlib.pyplot as plt

# Create dummy data
data = pd.DataFrame({
    'cusid': range(1, 101),
    'nov_bucket': ['101-600']*20 + ['0-100']*15 + ['601-650']*10 + ['651-700']*10 + ['701-750']*15 + ['751-800']*10 + ['801-850']*10 + ['850+']*10,
    'jan_bucket': ['101-600']*18 + ['0-100']*18 + ['601-650']*12 + ['651-700']*12 + ['701-750']*13 + ['751-800']*10 + ['801-850']*10 + ['850+']*7,
    'feb_bucket': ['101-600']*15 + ['0-100']*20 + ['601-650']*15 + ['651-700']*10 + ['701-750']*10 + ['751-800']*10 + ['801-850']*10 + ['850+']*10,
    'apr_bucket': ['101-600']*17 + ['0-100']*17 + ['601-650']*14 + ['651-700']*12 + ['701-750']*15 + ['751-800']*10 + ['801-850']*10 + ['850+']*5
})

# Define the ordered bands
bands = [
    '<0 (null)',
    '0-100',
    '101-600',
    '601-650',
    '651-700',
    '701-750',
    '751-800',
    '801-850',
    '850+'
]

# Distribution of buckets for each month
bucket_counts_nov = data['nov_bucket'].value_counts().reindex(bands).fillna(0)
bucket_counts_jan = data['jan_bucket'].value_counts().reindex(bands).fillna(0)
bucket_counts_feb = data['feb_bucket'].value_counts().reindex(bands).fillna(0)
bucket_counts_apr = data['apr_bucket'].value_counts().reindex(bands).fillna(0)

# Combine the value counts into a single DataFrame
bucket_counts = pd.DataFrame({
    'November': bucket_counts_nov,
    'January': bucket_counts_jan,
    'February': bucket_counts_feb,
    'April': bucket_counts_apr
})

# Transform the DataFrame to a format suitable for a line plot
bucket_counts = bucket_counts.reset_index().melt(id_vars='index', var_name='Month', value_name='Count')
bucket_counts = bucket_counts.rename(columns={'index': 'Bucket'})

# Plot the data as a single line chart
plt.figure(figsize=(12, 8))

for bucket in bands:
    subset = bucket_counts[bucket_counts['Bucket'] == bucket]
    plt.plot(subset['Month'], subset['Count'], marker='o', label=bucket)

plt.xlabel('Month')
plt.ylabel('Number of Customers')
plt.title('Distribution of CIBIL Score Buckets Over Months')
plt.legend(title='Buckets', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()












import pandas as pd
import plotly.graph_objects as go

# Specify the file location
file_path = 'path_to_your_file/simple.xlsx'  # Replace with your actual file path

# Load your data from Excel
data = pd.read_excel(file_path, engine='openpyxl')

# Ensure the columns are named correctly
data.columns = ['cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score']

# Define score buckets
def assign_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    elif 701 <= score <= 750:
        return '701-750'
    elif 751 <= score <= 800:
        return '751-800'
    elif 801 <= score <= 850:
        return '801-850'
    else:
        return '850+'

# Apply score buckets and prefix with month names
data['nov_bucket'] = 'Nov-' + data['nov_score'].apply(assign_bucket)
data['jan_bucket'] = 'Jan-' + data['jan_score'].apply(assign_bucket)
data['feb_bucket'] = 'Feb-' + data['feb_score'].apply(assign_bucket)
data['apr_bucket'] = 'Apr-' + data['apr_score'].apply(assign_bucket)

# Determine score changes
data['score_changed'] = (data['nov_bucket'] != data['jan_bucket']) | \
                        (data['jan_bucket'] != data['feb_bucket']) | \
                        (data['feb_bucket'] != data['apr_bucket'])

# Define the simplified buckets for filter option 3
def assign_simplified_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    else:
        return '700+'

# Apply simplified buckets and prefix with month names
data['nov_simplified_bucket'] = 'Nov-' + data['nov_score'].apply(assign_simplified_bucket)
data['jan_simplified_bucket'] = 'Jan-' + data['jan_score'].apply(assign_simplified_bucket)
data['feb_simplified_bucket'] = 'Feb-' + data['feb_score'].apply(assign_simplified_bucket)
data['apr_simplified_bucket'] = 'Apr-' + data['apr_score'].apply(assign_simplified_bucket)

# Function to create Sankey diagrams
def create_sankey(df, cols):
    unique_buckets = sorted(pd.unique(df[cols].values.ravel('K')))
    node_indices = {bucket: i for i, bucket in enumerate(unique_buckets)}

    links = []
    for i in range(len(cols) - 1):
        transition_counts = df.groupby([cols[i], cols[i + 1]]).size().reset_index(name='count')
        for _, row in transition_counts.iterrows():
            src, tgt = row[cols[i]], row[cols[i + 1]]
            links.append(dict(source=node_indices[src], target=node_indices[tgt], value=row['count']))

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            line=dict(color="black", width=0.5),
            label=unique_buckets
        ),
        link=dict(
            source=[link['source'] for link in links],
            target=[link['target'] for link in links],
            value=[link['value'] for link in links]
        )
    )])

    return fig

# Create Sankey charts
fig_overall = create_sankey(data, ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_changed = create_sankey(data[data['score_changed']], ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_simplified = create_sankey(data, ['nov_simplified_bucket', 'jan_simplified_bucket', 'feb_simplified_bucket', 'apr_simplified_bucket'])

# Show figures
fig_overall.show()
fig_changed.show()
fig_simplified.show()











import pandas as pd
import plotly.graph_objects as go

# Specify the file location
file_path = 'path_to_your_file/simple.xlsx'  # Replace with your actual file path

# Load your data from Excel
data = pd.read_excel(file_path, engine='openpyxl')

# Ensure the columns are named correctly
data.columns = ['cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score']

# Define score buckets
def assign_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    elif 701 <= score <= 750:
        return '701-750'
    elif 751 <= score <= 800:
        return '751-800'
    elif 801 <= score <= 850:
        return '801-850'
    else:
        return '850+'

# Apply score buckets
data['nov_bucket'] = data['nov_score'].apply(assign_bucket)
data['jan_bucket'] = data['jan_score'].apply(assign_bucket)
data['feb_bucket'] = data['feb_score'].apply(assign_bucket)
data['apr_bucket'] = data['apr_score'].apply(assign_bucket)

# Determine score changes
data['score_changed'] = (data['nov_bucket'] != data['jan_bucket']) | \
                        (data['jan_bucket'] != data['feb_bucket']) | \
                        (data['feb_bucket'] != data['apr_bucket'])

# Define the simplified buckets for filter option 3
def assign_simplified_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    else:
        return '700+'

# Apply simplified buckets
data['nov_simplified_bucket'] = data['nov_score'].apply(assign_simplified_bucket)
data['jan_simplified_bucket'] = data['jan_score'].apply(assign_simplified_bucket)
data['feb_simplified_bucket'] = data['feb_score'].apply(assign_simplified_bucket)
data['apr_simplified_bucket'] = data['apr_score'].apply(assign_simplified_bucket)

# Function to create Sankey diagrams
def create_sankey(df, cols):
    unique_buckets = sorted(pd.unique(df[cols].values.ravel('K')), reverse=True)
    node_indices = {bucket: i for i, bucket in enumerate(unique_buckets)}

    links = []
    for i in range(len(cols) - 1):
        transition_counts = df.groupby([cols[i], cols[i + 1]]).size().reset_index(name='count')
        for _, row in transition_counts.iterrows():
            src, tgt = row[cols[i]], row[cols[i + 1]]
            links.append(dict(source=node_indices[src], target=node_indices[tgt], value=row['count']))

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            line=dict(color="black", width=0.5),
            label=unique_buckets
        ),
        link=dict(
            source=[link['source'] for link in links],
            target=[link['target'] for link in links],
            value=[link['value'] for link in links]
        )
    )])

    return fig

# Create Sankey charts
fig_overall = create_sankey(data, ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_changed = create_sankey(data[data['score_changed']], ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_simplified = create_sankey(data, ['nov_simplified_bucket', 'jan_simplified_bucket', 'feb_simplified_bucket', 'apr_simplified_bucket'])

# Show figures
fig_overall.show()
fig_changed.show()
fig_simplified.show()










import os
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import dash
from dash import dcc, html
from dash.dependencies import Input, Output

# Specify the file location
file_path = 'path_to_your_file/cibil_scores.xlsx'  # Replace with your actual file path

# Step 1: Check if the file exists
if not os.path.exists(file_path):
    raise FileNotFoundError(f"The file at {file_path} does not exist.")

# Step 2: Read the file in chunks
chunk_size = 10000
chunks = []

try:
    for chunk in pd.read_excel(file_path, engine='openpyxl', chunksize=chunk_size):
        print(chunk.head())  # Print first few rows of each chunk for verification
        chunks.append(chunk)
except Exception as e:
    print(f"Error reading chunk: {e}")
    raise

# Check if chunks were read successfully
if not chunks:
    raise ValueError("No data was read from the file.")

# Combine chunks into a single DataFrame
data = pd.concat(chunks, axis=0)
print("Data loaded successfully")
print("First few rows of data:\n", data.head())

# Assuming the columns are 'cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score'
data.columns = ['cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score']

# Check data types and ensure all columns are numeric where expected
print("Data types:\n", data.dtypes)

# Define score buckets function
def assign_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    elif 701 <= score <= 750:
        return '701-750'
    elif 751 <= score <= 800:
        return '751-800'
    elif 801 <= score <= 850:
        return '801-850'
    else:
        return '850+'

# Apply score buckets
data['nov_bucket'] = data['nov_score'].apply(assign_bucket)
data['jan_bucket'] = data['jan_score'].apply(assign_bucket)
data['feb_bucket'] = data['feb_score'].apply(assign_bucket)
data['apr_bucket'] = data['apr_score'].apply(assign_bucket)

# Determine score changes
data['score_changed'] = (data['nov_bucket'] != data['jan_bucket']) | \
                        (data['jan_bucket'] != data['feb_bucket']) | \
                        (data['feb_bucket'] != data['apr_bucket'])

# Define the simplified buckets for filter option 3
def assign_simplified_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    else:
        return '700+'

# Apply simplified buckets
data['nov_simplified_bucket'] = data['nov_score'].apply(assign_simplified_bucket)
data['jan_simplified_bucket'] = data['jan_score'].apply(assign_simplified_bucket)
data['feb_simplified_bucket'] = data['feb_score'].apply(assign_simplified_bucket)
data['apr_simplified_bucket'] = data['apr_score'].apply(assign_simplified_bucket)

# Step 5: Function to create Sankey diagrams
def create_sankey(df, cols):
    # Get unique buckets and sort them in decreasing order
    unique_buckets = sorted(pd.unique(df[cols].values.ravel('K')), reverse=True)
    node_indices = {bucket: i for i, bucket in enumerate(unique_buckets)}

    links = []
    for i in range(len(cols) - 1):
        transition_counts = df.groupby([cols[i], cols[i + 1]]).size().reset_index(name='count')
        for _, row in transition_counts.iterrows():
            src, tgt = row[cols[i]], row[cols[i + 1]]
            links.append(dict(source=node_indices[src], target=node_indices[tgt], value=row['count']))

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            line=dict(color="black", width=0.5),
            label=unique_buckets
        ),
        link=dict(
            source=[link['source'] for link in links],
            target=[link['target'] for link in links],
            value=[link['value'] for link in links]
        )
    )])

    return fig

# Step 6: Create Sankey charts
fig_overall = create_sankey(data, ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_changed = create_sankey(data[data['score_changed']], ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_simplified = create_sankey(data, ['nov_simplified_bucket', 'jan_simplified_bucket', 'feb_simplified_bucket', 'apr_simplified_bucket'])

# Save figures as HTML for embedding in Dash
fig_overall.write_html('fig_overall.html')
fig_changed.write_html('fig_changed.html')
fig_simplified.write_html('fig_simplified.html')

# Step 7: Create Dash app
app = dash.Dash(__name__)

app.layout = html.Div([
    html.H1("CIBIL Score Transitions Sankey Chart"),
    dcc.Dropdown(
        id='filter-dropdown',
        options=[
            {'label': 'Overall Score View', 'value': 'overall'},
            {'label': 'Score Change View', 'value': 'changed'},
            {'label': 'Simplified Buckets View', 'value': 'simplified'}
        ],
        value='overall'
    ),
    html.Div(id='sankey-container')
])

@app.callback(
    Output('sankey-container', 'children'),
    [Input('filter-dropdown', 'value')]
)
def update_sankey(filter_value):
    if filter_value == 'overall':
        return html.Iframe(srcDoc=open('fig_overall.html').read(), width='100%', height='600')
    elif filter_value == 'changed':
        return html.Iframe(srcDoc=open('fig_changed.html').read(), width='100%', height='600')
    elif filter_value == 'simplified':
        return html.Iframe(srcDoc=open('fig_simplified.html').read(), width='100%', height='600')

if __name__ == '__main__':
    app.run_server(debug=True)












import pandas as pd

# Specify the chunk size and the position of the problematic byte
chunk_size = 10000
problematic_position = 305229

# Calculate the chunk number and row number within the chunk
chunk_number = problematic_position // chunk_size
row_number = problematic_position % chunk_size

# Read the file in chunks
chunk_list = []
try:
    for i, chunk in enumerate(pd.read_excel('cibil_scores.xlsx', engine='openpyxl', chunksize=chunk_size)):
        chunk_list.append(chunk)
        if i == chunk_number:
            print(f"Inspecting chunk {i + 1}")
            print(chunk.iloc[row_number - 5:row_number + 5])  # Print surrounding rows for context
except Exception as e:
    print(f"Error loading data: {e}")

# Combine all chunks if no error occurs
if not chunk_list:
    data = pd.concat(chunk_list, axis=0)
    print("Data loaded successfully")
else:
    data = pd.DataFrame()



import pandas as pd
import numpy as np
import plotly.graph_objects as go
import dash
from dash import dcc, html
from dash.dependencies import Input, Output

# Step 1: Load your data from Excel in chunks and identify the problematic row
chunk_size = 10000
problematic_position = 305229

# Calculate the chunk number and row number within the chunk
chunk_number = problematic_position // chunk_size
row_number = problematic_position % chunk_size

chunk_list = []
try:
    for i, chunk in enumerate(pd.read_excel('cibil_scores.xlsx', engine='openpyxl', chunksize=chunk_size)):
        chunk_list.append(chunk)
        if i == chunk_number:
            print(f"Inspecting chunk {i + 1}")
            print(chunk.iloc[row_number - 5:row_number + 5])  # Print surrounding rows for context
except Exception as e:
    print(f"Error loading data: {e}")
    raise

# Combine all chunks if no error occurs
if chunk_list:
    data = pd.concat(chunk_list, axis=0)
    print("Data loaded successfully")
else:
    data = pd.DataFrame()

# Verify the data
print("Data Columns:", data.columns)
print("First few rows of data:\n", data.head())

# Assuming the columns are 'cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score'
data.columns = ['cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score']

# Check data types and ensure all columns are numeric where expected
print("Data types:\n", data.dtypes)

# Define score buckets function
def assign_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    elif 701 <= score <= 750:
        return '701-750'
    elif 751 <= score <= 800:
        return '751-800'
    elif 801 <= score <= 850:
        return '801-850'
    else:
        return '850+'

# Apply score buckets
data['nov_bucket'] = data['nov_score'].apply(assign_bucket)
data['jan_bucket'] = data['jan_score'].apply(assign_bucket)
data['feb_bucket'] = data['feb_score'].apply(assign_bucket)
data['apr_bucket'] = data['apr_score'].apply(assign_bucket)

# Determine score changes
data['score_changed'] = (data['nov_bucket'] != data['jan_bucket']) | \
                        (data['jan_bucket'] != data['feb_bucket']) | \
                        (data['feb_bucket'] != data['apr_bucket'])

# Define the simplified buckets for filter option 3
def assign_simplified_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    else:
        return '700+'

# Apply simplified buckets
data['nov_simplified_bucket'] = data['nov_score'].apply(assign_simplified_bucket)
data['jan_simplified_bucket'] = data['jan_score'].apply(assign_simplified_bucket)
data['feb_simplified_bucket'] = data['feb_score'].apply(assign_simplified_bucket)
data['apr_simplified_bucket'] = data['apr_score'].apply(assign_simplified_bucket)

# Step 5: Function to create Sankey diagrams
def create_sankey(df, cols):
    # Get unique buckets and sort them in decreasing order
    unique_buckets = sorted(pd.unique(df[cols].values.ravel('K')), reverse=True)
    node_indices = {bucket: i for i, bucket in enumerate(unique_buckets)}

    links = []
    for i in range(len(cols) - 1):
        transition_counts = df.groupby([cols[i], cols[i + 1]]).size().reset_index(name='count')
        for _, row in transition_counts.iterrows():
            src, tgt = row[cols[i]], row[cols[i + 1]]
            links.append(dict(source=node_indices[src], target=node_indices[tgt], value=row['count']))

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            line=dict(color="black", width=0.5),
            label=unique_buckets
        ),
        link=dict(
            source=[link['source'] for link in links],
            target=[link['target'] for link in links],
            value=[link['value'] for link in links]
        )
    )])

    return fig

# Step 6: Create Sankey charts
fig_overall = create_sankey(data, ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_changed = create_sankey(data[data['score_changed']], ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_simplified = create_sankey(data, ['nov_simplified_bucket', 'jan_simplified_bucket', 'feb_simplified_bucket', 'apr_simplified_bucket'])

# Save figures as HTML for embedding in Dash
fig_overall.write_html('fig_overall.html')
fig_changed.write_html('fig_changed.html')
fig_simplified.write_html('fig_simplified.html')

# Step 7: Create Dash app
app = dash.Dash(__name__)

app.layout = html.Div([
    html.H1("CIBIL Score Transitions Sankey Chart"),
    dcc.Dropdown(
        id='filter-dropdown',
        options=[
            {'label': 'Overall Score View', 'value': 'overall'},
            {'label': 'Score Change View', 'value': 'changed'},
            {'label': 'Simplified Buckets View', 'value': 'simplified'}
        ],
        value='overall'
    ),
    html.Div(id='sankey-container')
])

@app.callback(
    Output('sankey-container', 'children'),
    [Input('filter-dropdown', 'value')]
)
def update_sankey(filter_value):
    if filter_value == 'overall':
        return html.Iframe(srcDoc=open('fig_overall.html').read(), width='100%', height='600')
    elif filter_value == 'changed':
        return html.Iframe(srcDoc=open('fig_changed.html').read(), width='100%', height='600')
    elif filter_value == 'simplified':
        return html.Iframe(srcDoc=open('fig_simplified.html').read(), width='100%', height='600')

if __name__ == '__main__':
    app.run_server(debug=True)












import pandas as pd
import numpy as np
import plotly.graph_objects as go
import dash
from dash import dcc, html
from dash.dependencies import Input, Output

# Load your data from Excel with debugging
try:
    data = pd.read_excel('cibil_scores.xlsx', engine='openpyxl')
    print("Data loaded successfully")
except Exception as e:
    print(f"Error loading data: {e}")

# Verify the columns
print("Columns:", data.columns)

# Assuming the columns are 'cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score'
data.columns = ['cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score']

# Define score buckets
def assign_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    elif 701 <= score <= 750:
        return '701-750'
    elif 751 <= score <= 800:
        return '751-800'
    elif 801 <= score <= 850:
        return '801-850'
    else:
        return '850+'

# Apply score buckets
data['nov_bucket'] = data['nov_score'].apply(assign_bucket)
data['jan_bucket'] = data['jan_score'].apply(assign_bucket)
data['feb_bucket'] = data['feb_score'].apply(assign_bucket)
data['apr_bucket'] = data['apr_score'].apply(assign_bucket)

# Determine score changes
data['score_changed'] = (data['nov_bucket'] != data['jan_bucket']) | \
                        (data['jan_bucket'] != data['feb_bucket']) | \
                        (data['feb_bucket'] != data['apr_bucket'])

# Define the simplified buckets for filter option 3
def assign_simplified_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    else:
        return '700+'

# Apply simplified buckets
data['nov_simplified_bucket'] = data['nov_score'].apply(assign_simplified_bucket)
data['jan_simplified_bucket'] = data['jan_score'].apply(assign_simplified_bucket)
data['feb_simplified_bucket'] = data['feb_score'].apply(assign_simplified_bucket)
data['apr_simplified_bucket'] = data['apr_score'].apply(assign_simplified_bucket)

# Function to create Sankey diagrams
def create_sankey(df, cols):
    # Get unique buckets and sort them in decreasing order
    unique_buckets = sorted(pd.unique(df[cols].values.ravel('K')), reverse=True)
    node_indices = {bucket: i for i, bucket in enumerate(unique_buckets)}

    links = []
    for i in range(len(cols) - 1):
        transition_counts = df.groupby([cols[i], cols[i + 1]]).size().reset_index(name='count')
        for _, row in transition_counts.iterrows():
            src, tgt = row[cols[i]], row[cols[i + 1]]
            links.append(dict(source=node_indices[src], target=node_indices[tgt], value=row['count']))

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            line=dict(color="black", width=0.5),
            label=unique_buckets
        ),
        link=dict(
            source=[link['source'] for link in links],
            target=[link['target'] for link in links],
            value=[link['value'] for link in links]
        )
    )])

    return fig

# Create Sankey charts
fig_overall = create_sankey(data, ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_changed = create_sankey(data[data['score_changed']], ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_simplified = create_sankey(data, ['nov_simplified_bucket', 'jan_simplified_bucket', 'feb_simplified_bucket', 'apr_simplified_bucket'])

# Save figures as HTML for embedding in Dash
fig_overall.write_html('fig_overall.html')
fig_changed.write_html('fig_changed.html')
fig_simplified.write_html('fig_simplified.html')

# Create Dash app
app = dash.Dash(__name__)

app.layout = html.Div([
    html.H1("CIBIL Score Transitions Sankey Chart"),
    dcc.Dropdown(
        id='filter-dropdown',
        options=[
            {'label': 'Overall Score View', 'value': 'overall'},
            {'label': 'Score Change View', 'value': 'changed'},
            {'label': 'Simplified Buckets View', 'value': 'simplified'}
        ],
        value='overall'
    ),
    html.Div(id='sankey-container')
])

@app.callback(
    Output('sankey-container', 'children'),
    [Input('filter-dropdown', 'value')]
)
def update_sankey(filter_value):
    if filter_value == 'overall':
        return html.Iframe(srcDoc=open('fig_overall.html').read(), width='100%', height='600')
    elif filter_value == 'changed':
        return html.Iframe(srcDoc=open('fig_changed.html').read(), width='100%', height='600')
    elif filter_value == 'simplified':
        return html.Iframe(srcDoc=open('fig_simplified.html').read(), width='100%', height='600')

if __name__ == '__main__':
    app.run_server(debug=True)









import pandas as pd
import numpy as np
import plotly.graph_objects as go
import dash
from dash import dcc, html
from dash.dependencies import Input, Output

# Load your data
data = pd.read_csv('cibil_scores.csv')

# Assuming the columns are 'cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score'
data.columns = ['cusid', 'nov_score', 'jan_score', 'feb_score', 'apr_score']

# Define score buckets
def assign_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    elif 701 <= score <= 750:
        return '701-750'
    elif 751 <= score <= 800:
        return '751-800'
    elif 801 <= score <= 850:
        return '801-850'
    else:
        return '850+'

# Apply score buckets
data['nov_bucket'] = data['nov_score'].apply(assign_bucket)
data['jan_bucket'] = data['jan_score'].apply(assign_bucket)
data['feb_bucket'] = data['feb_score'].apply(assign_bucket)
data['apr_bucket'] = data['apr_score'].apply(assign_bucket)

# Determine score changes
data['score_changed'] = (data['nov_bucket'] != data['jan_bucket']) | \
                        (data['jan_bucket'] != data['feb_bucket']) | \
                        (data['feb_bucket'] != data['apr_bucket'])

# Define the simplified buckets for filter option 3
def assign_simplified_bucket(score):
    if pd.isna(score):
        return '<0 (null)'
    if score < 0:
        return '<0 (null)'
    elif 0 <= score <= 100:
        return '0-100'
    elif 101 <= score <= 600:
        return '101-600'
    elif 601 <= score <= 650:
        return '601-650'
    elif 651 <= score <= 700:
        return '651-700'
    else:
        return '700+'

# Apply simplified buckets
data['nov_simplified_bucket'] = data['nov_score'].apply(assign_simplified_bucket)
data['jan_simplified_bucket'] = data['jan_score'].apply(assign_simplified_bucket)
data['feb_simplified_bucket'] = data['feb_score'].apply(assign_simplified_bucket)
data['apr_simplified_bucket'] = data['apr_score'].apply(assign_simplified_bucket)

# Function to create Sankey diagrams
def create_sankey(df, cols):
    # Get unique buckets and sort them in decreasing order
    unique_buckets = sorted(pd.unique(df[cols].values.ravel('K')), reverse=True)
    node_indices = {bucket: i for i, bucket in enumerate(unique_buckets)}

    links = []
    for i in range(len(cols) - 1):
        transition_counts = df.groupby([cols[i], cols[i + 1]]).size().reset_index(name='count')
        for _, row in transition_counts.iterrows():
            src, tgt = row[cols[i]], row[cols[i + 1]]
            links.append(dict(source=node_indices[src], target=node_indices[tgt], value=row['count']))

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            line=dict(color="black", width=0.5),
            label=unique_buckets
        ),
        link=dict(
            source=[link['source'] for link in links],
            target=[link['target'] for link in links],
            value=[link['value'] for link in links]
        )
    )])

    return fig

# Create Sankey charts
fig_overall = create_sankey(data, ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_changed = create_sankey(data[data['score_changed']], ['nov_bucket', 'jan_bucket', 'feb_bucket', 'apr_bucket'])
fig_simplified = create_sankey(data, ['nov_simplified_bucket', 'jan_simplified_bucket', 'feb_simplified_bucket', 'apr_simplified_bucket'])

# Save figures as HTML for embedding in Dash
fig_overall.write_html('fig_overall.html')
fig_changed.write_html('fig_changed.html')
fig_simplified.write_html('fig_simplified.html')

# Create Dash app
app = dash.Dash(__name__)

app.layout = html.Div([
    html.H1("CIBIL Score Transitions Sankey Chart"),
    dcc.Dropdown(
        id='filter-dropdown',
        options=[
            {'label': 'Overall Score View', 'value': 'overall'},
            {'label': 'Score Change View', 'value': 'changed'},
            {'label': 'Simplified Buckets View', 'value': 'simplified'}
        ],
        value='overall'
    ),
    html.Div(id='sankey-container')
])

@app.callback(
    Output('sankey-container', 'children'),
    [Input('filter-dropdown', 'value')]
)
def update_sankey(filter_value):
    if filter_value == 'overall':
        return html.Iframe(srcDoc=open('fig_overall.html').read(), width='100%', height='600')
    elif filter_value == 'changed':
        return html.Iframe(srcDoc=open('fig_changed.html').read(), width='100%', height='600')
    elif filter_value == 'simplified':
        return html.Iframe(srcDoc=open('fig_simplified.html').read(), width='100%', height='600')

if __name__ == '__main__':
    app.run_server(debug=True)
