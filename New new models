import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer

# Load the data
data = pd.read_csv('transactions.csv')

# Correct data types
data['ACCT'] = data['ACCT'].astype(str)
data['TRAN_AMT'] = pd.to_numeric(data['TRAN_AMT'], errors='coerce')
data['Date'] = pd.to_datetime(data['Date'])
data['AGE_NUM'] = data['AGE_NUM'].astype(int)
data['JOB_TITLE'] = data['JOB_TITLE'].astype(str)
data['Sector'] = data['Sector'].astype(str)

# Define features and target
X = data.drop(['ACCT', 'Date', 'Sector'], axis=1)
y = data['Sector']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessing for numerical features
numeric_features = ['TRAN_AMT', 'AGE_NUM']
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

# Preprocessing for categorical features
categorical_features = ['JOB_TITLE']
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

# ColumnTransformer for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

# Define the model with hyperparameter grid search
logistic_model = LogisticRegression(max_iter=1000, multi_class='multinomial')
param_grid = {
    'classifier__C': [0.1, 1, 10],
    'classifier__penalty': ['l1', 'l2'],
    'classifier__solver': ['liblinear', 'saga']
}

# Combine preprocessing and model into a pipeline
# Use ImbPipeline from imblearn to integrate SMOTE
pipeline = ImbPipeline(steps=[('preprocessor', preprocessor),
                              ('smote', SMOTE(random_state=42)),
                              ('polynomial', PolynomialFeatures(degree=2, include_bias=False)),
                              ('classifier', logistic_model)])

# Perform grid search
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best estimator from grid search
best_model = grid_search.best_estimator_

# Predictions and Evaluation
y_pred = best_model.predict(X_test)

# Accuracy and classification report
print(classification_report(y_test, y_pred))

# Confusion Matrix
conf_mat = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()










import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import make_pipeline as make_pipeline_imb
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer

# Load the data
data = pd.read_csv('transactions.csv')

# Correct data types
data['ACCT'] = data['ACCT'].astype(str)
data['TRAN_AMT'] = pd.to_numeric(data['TRAN_AMT'], errors='coerce')
data['Date'] = pd.to_datetime(data['Date'])
data['AGE_NUM'] = data['AGE_NUM'].astype(int)
data['JOB_TITLE'] = data['JOB_TITLE'].astype(str)
data['Sector'] = data['Sector'].astype(str)

# Initialize label encoder for the target variable
label_encoder = LabelEncoder()

# Encode the 'Sector' labels to integers
y_encoded = label_encoder.fit_transform(data['Sector'])

# Split the data
X = data.drop(['ACCT', 'Date', 'Sector'], axis=1)
y = y_encoded
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define column transformer for preprocessing
numeric_features = ['TRAN_AMT', 'AGE_NUM']
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_features = ['JOB_TITLE']
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

# Initialize the XGBClassifier
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')

# Create a pipeline with preprocessing, SMOTE, and the classifier
pipeline = make_pipeline_imb(preprocessor,
                             SMOTE(random_state=42),
                             xgb_model)

# Define hyperparameter space for GridSearch
param_grid = {
    'xgbclassifier__max_depth': [3, 5, 7],
    'xgbclassifier__learning_rate': [0.01, 0.1, 0.3],
    'xgbclassifier__n_estimators': [100, 200],
    'xgbclassifier__min_child_weight': [1, 3, 5]
}

# GridSearchCV
grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best estimator
best_model = grid_search.best_estimator_

# Predictions
y_pred = best_model.predict(X_test)

# Convert the predicted labels back to original string labels for interpretability
y_pred_labels = label_encoder.inverse_transform(y_pred)

# Evaluation
print(classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))

# Confusion Matrix
conf_mat = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()
