/* Step 1: Determine acquisition date (earliest of product open dates) */
data customer_acquisition;
    set customer_base;
    acquisition_date = min(of card_open_date ploc_open_date loan_open_date);  /* Add all product dates here */
    if acquisition_date >= '01JAN2024'd;

    mob3_date = intnx('month', acquisition_date, 2, 'b');
    mob3_cube_name = "cust_cube_" || lowcase(put(mob3_date, monname3.)) || put(mob3_date, year2.) || "_data";
    mob3_var_suffix = put(mob3_date, mmyyn4.);  /* e.g., 0324 for Mar 2024 */
    format acquisition_date mob3_date date9.;
run;

/* Step 2: Get unique cube names + suffixes */
proc sql noprint;
    select distinct mob3_cube_name, mob3_var_suffix 
        into :cube_list separated by ' ', :suffix_list separated by ' '
    from customer_acquisition;
quit;

/* Step 3: Loop through cubes, use correct TRB variable */
%macro fetch_mob3_trb;
    %let i = 1;
    %do %while (%scan(&cube_list, &i) ne );
        %let cube_ds = %scan(&cube_list, &i);
        %let suffix = %scan(&suffix_list, &i);
        %let trb_var = trb_bal_&suffix._uniq;

        proc sql;
            create table trb_&i as
            select 
                a.cust_id,
                a.acquisition_date,
                a.mob3_date,
                b.&trb_var as mob3_trb
            from customer_acquisition a
            inner join cube1.&cube_ds b
                on a.cust_id = b.cust_id
            where a.mob3_cube_name = "&cube_ds";
        quit;

        %let i = %eval(&i + 1);
    %end;

    /* Combine all temp results */
    data final_mob3_trb;
        set 
        %do j = 1 %to %eval(&i - 1);
            trb_&j
        %end;
        ;
    run;
%mend;

%fetch_mob3_trb;






/* Step 1: Get acquisition date (earliest of all product open dates) */
data customer_acquisition;
    set customer_base;

    acquisition_date = min(of card_open_date ploc_open_date loan_open_date); /* add all relevant products */
    if acquisition_date >= '01JAN2024'd;

    mob3_date = intnx('month', acquisition_date, 2, 'b'); /* MOB3 = Acq + 2 months */
    mob3_cube_name = "cust_cube_" || 
                     lowcase(put(mob3_date, monname3.)) || 
                     put(mob3_date, year2.) || 
                     "_data";  /* e.g., cust_cube_mar24_data */

    format acquisition_date mob3_date date9.;
run;

/* Step 2: Extract unique cube dataset names */
proc sql noprint;
    select distinct mob3_cube_name into :cube_list separated by ' '
    from customer_acquisition;
quit;

/* Step 3: Loop through each cube dataset and extract MOB3 TRB */
%macro fetch_mob3_trb;
    %let i = 1;
    %do %while (%scan(&cube_list, &i) ne );
        %let cube_ds = %scan(&cube_list, &i);

        proc sql;
            create table trb_&i as
            select 
                a.cust_id,
                a.acquisition_date,
                a.mob3_date,
                b.card_trb + b.ploc_trb + b.loan_trb as mob3_trb  /* or use total_trb if available */
            from customer_acquisition a
            inner join &cube_ds b
                on a.cust_id = b.cust_id
            where a.mob3_cube_name = "&cube_ds";
        quit;

        %let i = %eval(&i + 1);
    %end;

    /* Combine all cube outputs */
    data final_mob3_trb;
        set 
        %do j = 1 %to %eval(&i - 1);
            trb_&j
        %end;
        ;
    run;
%mend;

%fetch_mob3_trb;








/* Step 1: Derive acquisition date from all product open dates */
data customer_acquisition;
    set customer_base;

    acquisition_date = min(of card_open_date ploc_open_date loan_open_date); /* include all product columns */
    if acquisition_date >= '01JAN2024'd;

    mob3_date = intnx('month', acquisition_date, 2, 'b'); /* MOB3 = Acq + 2 months */
    mob3_cube = lowcase(put(mob3_date, monname3.)) || put(mob3_date, year2.); /* e.g., mar24 */
    format acquisition_date mob3_date date9.;
run;

/* Step 2: Extract unique cube months to dynamically loop */
proc sql noprint;
    select distinct mob3_cube into :cube_list separated by ' '
    from customer_acquisition;
quit;

/* Step 3: Loop through each cube and extract MOB3 TRB */
%macro fetch_mob3_trb_by_acquisition;
    %let i = 1;
    %do %while (%scan(&cube_list, &i) ne );
        %let cube = %scan(&cube_list, &i);

        proc sql;
            create table trb_&cube as
            select 
                a.cust_id,
                a.acquisition_date,
                a.mob3_date,
                /* Extract TRB for that month: either a total column, or sum individual product TRBs */
                b.card_trb + b.ploc_trb + b.loan_trb as mob3_trb
            from customer_acquisition a
            inner join cube_&cube b
                on a.cust_id = b.cust_id
            where a.mob3_cube = "&cube";
        quit;

        %let i = %eval(&i + 1);
    %end;

    /* Combine all extracted TRB records into one final table */
    data final_mob3_trb;
        set 
        %do j = 1 %to %eval(&i - 1);
            %let cube = %scan(&cube_list, &j);
            trb_&cube
        %end;
        ;
    run;
%mend;

%fetch_mob3_trb_by_acquisition;









# amount & freq model #
import pandas as pd
import numpy as np
from sklearn.preprocessing import RobustScaler
from sklearn.metrics.pairwise import cosine_similarity

def load_and_preprocess_data(filepath):
    df = pd.read_csv(filepath)
    df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
    df.dropna(inplace=True)
    # Initialize a count for each transaction
    df['TRAN_COUNT'] = 1
    return df

def generate_interaction_matrix(df, sectors, value_column):
    interaction_matrix = df.pivot_table(index='ACCT', columns='Sector', values=value_column, aggfunc='sum', fill_value=0)
    for sector in sectors:
        if sector not in interaction_matrix.columns:
            interaction_matrix[sector] = 0
    return interaction_matrix[sorted(sectors)]

def scale_and_combine_matrices(amount_matrix, frequency_matrix):
    scaler = RobustScaler()
    scaled_amount_matrix = scaler.fit_transform(amount_matrix)
    scaled_frequency_matrix = scaler.fit_transform(frequency_matrix)
    combined_matrix = (scaled_amount_matrix + scaled_frequency_matrix) / 2
    return pd.DataFrame(combined_matrix, index=amount_matrix.index, columns=amount_matrix.columns)

def calculate_cosine_similarity(matrix):
    return cosine_similarity(matrix)

def generate_hot_encoding(df, sectors):
    hot_encoded = pd.get_dummies(df[['ACCT', 'Sector']], columns=['Sector'], prefix='', prefix_sep='').groupby('ACCT').max()
    for sector in sectors:
        if sector not in hot_encoded.columns:
            hot_encoded[sector] = 0
    return hot_encoded[sorted(sectors)]

def get_recommendation_ranks(interaction_matrix, sector_similarity):
    scores = np.dot(interaction_matrix, sector_similarity)
    ranks = (-scores).argsort(axis=1).argsort(axis=1) + 1
    return pd.DataFrame(ranks, index=interaction_matrix.index, columns=interaction_matrix.columns)

def generate_transaction_ranks(df, sectors):
    interaction_matrix = generate_interaction_matrix(df, sectors, 'TRAN_AMT')  # Using 'TRAN_AMT' for transaction value
    transaction_ranks = interaction_matrix.rank(axis=1, method='max', ascending=False).astype(int)
    return transaction_ranks

def main():
    df = load_and_preprocess_data('data.csv')  # Ensure to replace 'data.csv' with your actual file name
    split_date = pd.to_datetime("2023-01-01")
    sectors = sorted(df['Sector'].unique())
    train_df, test_df = df[df['DATE'] < split_date], df[df['DATE'] >= split_date]

    # Generate interaction matrices for amounts and frequencies
    train_amount_matrix = generate_interaction_matrix(train_df, sectors, 'TRAN_AMT')
    train_frequency_matrix = generate_interaction_matrix(train_df, sectors, 'TRAN_COUNT')
    test_amount_matrix = generate_interaction_matrix(test_df, sectors, 'TRAN_AMT')
    test_frequency_matrix = generate_interaction_matrix(test_df, sectors, 'TRAN_COUNT')

    # Scale and combine matrices
    train_combined_matrix = scale_and_combine_matrices(train_amount_matrix, train_frequency_matrix)
    test_combined_matrix = scale_and_combine_matrices(test_amount_matrix, test_frequency_matrix)
    
    # Calculate cosine similarity based on the combined matrix
    sector_similarity = calculate_cosine_similarity(train_combined_matrix)
    
    # Generate hot encoding and transaction ranks
    train_hot_encoding = generate_hot_encoding(train_df, sectors)
    test_hot_encoding = generate_hot_encoding(test_df, sectors)
    test_transaction_ranks = generate_transaction_ranks(test_df, sectors)
    
    # Generate recommendations based on the combined matrix
    test_recommendations = get_recommendation_ranks(test_combined_matrix, sector_similarity)

    with pd.ExcelWriter('analysis_outputs.xlsx', engine='openpyxl') as writer:
        train_hot_encoding.to_excel(writer, sheet_name='Train Hot Encoding')
        test_hot_encoding.to_excel(writer, sheet_name='Test Hot Encoding')
        test_recommendations.to_excel(writer, sheet_name='Test Recommendations')
        test_transaction_ranks.to_excel(writer, sheet_name='Test Transaction Ranks')
        # Optionally export the combined scaled matrices and sector similarity if needed

    print("All requested outputs have been exported to 'analysis_outputs.xlsx'.")

if __name__ == "__main__":
    main()


#Use of percentage instead of scaling
# change sum to count for freq in same code 

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

def load_and_preprocess_data(filepath):
    df = pd.read_csv(filepath)
    df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
    df.dropna(inplace=True)
    # Initialize a count for each transaction
    df['TRAN_COUNT'] = 1
    return df

def generate_interaction_matrix(df, sectors, value_column='TRAN_AMT'):
    interaction_matrix = df.pivot_table(index='ACCT', columns='Sector', values=value_column, aggfunc='sum', fill_value=0)
    for sector in sectors:
        if sector not in interaction_matrix.columns:
            interaction_matrix[sector] = 0
    # Calculate percentage of each sector from overall amount
    interaction_matrix_percentage = interaction_matrix.div(interaction_matrix.sum(axis=1), axis=0) * 100
    return interaction_matrix_percentage[sorted(sectors)]

def calculate_cosine_similarity(matrix):
    return cosine_similarity(matrix)

def generate_hot_encoding(df, sectors):
    hot_encoded = pd.get_dummies(df[['ACCT', 'Sector']], columns=['Sector'], prefix='', prefix_sep='').groupby('ACCT').max()
    for sector in sectors:
        if sector not in hot_encoded.columns:
            hot_encoded[sector] = 0
    return hot_encoded[sorted(sectors)]

def get_recommendation_ranks(interaction_matrix, sector_similarity):
    scores = np.dot(interaction_matrix, sector_similarity)
    ranks = (-scores).argsort(axis=1).argsort(axis=1) + 1
    return pd.DataFrame(ranks, index=interaction_matrix.index, columns=interaction_matrix.columns)

def generate_transaction_ranks(df, sectors):
    interaction_matrix = generate_interaction_matrix(df, sectors)  # Using 'TRAN_AMT' for transaction value
    transaction_ranks = interaction_matrix.rank(axis=1, method='max', ascending=False).astype(int)
    return transaction_ranks

def main():
    df = load_and_preprocess_data('data.csv')  # Ensure to replace 'data.csv' with your actual file name
    split_date = pd.to_datetime("2023-01-01")
    sectors = sorted(df['Sector'].unique())
    train_df, test_df = df[df['DATE'] < split_date], df[df['DATE'] >= split_date]

    # Generate interaction matrices for amounts (percentage)
    train_amount_matrix = generate_interaction_matrix(train_df, sectors)
    test_amount_matrix = generate_interaction_matrix(test_df, sectors)
    
    # Calculate cosine similarity based on the percentage matrix
    sector_similarity = calculate_cosine_similarity(train_amount_matrix)
    
    # Generate hot encoding and transaction ranks
    train_hot_encoding = generate_hot_encoding(train_df, sectors)
    test_hot_encoding = generate_hot_encoding(test_df, sectors)
    test_transaction_ranks = generate_transaction_ranks(test_df, sectors)
    
    # Generate recommendations based on the percentage matrix
    test_recommendations = get_recommendation_ranks(test_amount_matrix, sector_similarity)

    with pd.ExcelWriter('analysis_outputs.xlsx', engine='openpyxl') as writer:
        train_hot_encoding.to_excel(writer, sheet_name='Train Hot Encoding')
        test_hot_encoding.to_excel(writer, sheet_name='Test Hot Encoding')
        test_recommendations.to_excel(writer, sheet_name='Test Recommendations')
        test_transaction_ranks.to_excel(writer, sheet_name='Test Transaction Ranks')
        # Optionally export the percentage matrices if needed

    print("All requested outputs have been exported to 'analysis_outputs.xlsx'.")

if __name__ == "__main__":
    main()



# All output in one file 

def main():
    df = load_and_preprocess_data('data.csv')  # Make sure this points to your actual data file
    split_date = pd.to_datetime("2023-01-01")
    sectors = sorted(df['Sector'].unique())
    train_df, test_df = df[df['DATE'] < split_date], df[df['DATE'] >= split_date]

    # Assuming these functions are defined and return DataFrames with an 'ACCT' column and sector columns
    train_hot_encoding = generate_hot_encoding(train_df, sectors)
    test_hot_encoding = generate_hot_encoding(test_df, sectors)
    train_combined_matrix = generate_interaction_matrix(train_df, sectors, 'TRAN_AMT', aggfunc='sum') # For recommendations
    test_transaction_ranks = generate_transaction_ranks(test_df, sectors)

    # Assuming the generation of train recommendations is similar to test recommendations
    sector_similarity = calculate_cosine_similarity(train_combined_matrix)  # Based on the combined interaction matrix for train
    train_recommendations = get_recommendation_ranks(train_combined_matrix, sector_similarity)  # Using train data for demonstration
    
    # Write to Excel with specified order
    with pd.ExcelWriter('analysis_outputs.xlsx', engine='openpyxl') as writer:
        # Calculate start column for each DataFrame based on the widths of the preceding ones + 2 columns for spacing
        start_col = 0
        
        # Train Recommendations
        train_recommendations.to_excel(writer, sheet_name='Combined Analysis', startrow=0, startcol=start_col, index=True)
        start_col += train_recommendations.shape[1] + 2

        # Test Transaction Ranks
        test_transaction_ranks.to_excel(writer, sheet_name='Combined Analysis', startrow=0, startcol=start_col, index=True)
        start_col += test_transaction_ranks.shape[1] + 2

        # Train Hot Encoding
        train_hot_encoding.reset_index().to_excel(writer, sheet_name='Combined Analysis', startrow=0, startcol=start_col, index=False)
        start_col += train_hot_encoding.shape[1] + 3  # +1 for the 'ACCT' column after resetting index

        # Test Hot Encoding
        test_hot_encoding.reset_index().to_excel(writer, sheet_name='Combined Analysis', startrow=0, startcol=start_col, index=False)

    print("All data exported to 'analysis_outputs.xlsx' in the 'Combined Analysis' sheet.")

if __name__ == "__main__":
    main()
