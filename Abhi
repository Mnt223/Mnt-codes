import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

def load_and_preprocess_data(filepath):
    # Load the data from a CSV file
    df = pd.read_csv(filepath)
    print("Data loaded.")
    
    # Convert the 'DATE' column to datetime format, handling errors by coercion
    df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
    print("Date column processed.")
    
    # Remove rows with any missing values
    df.dropna(inplace=True)
    print("Missing values removed.")
    return df

def generate_interaction_matrix(df, sectors):
    # Pivot the data to create an interaction matrix
    interaction_matrix = df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='sum', fill_value=0)
    print("Initial interaction matrix generated.")
    
    # Ensure all sectors are included, adding missing ones as columns with 0s
    for sector in sectors:
        if sector not in interaction_matrix.columns:
            interaction_matrix[sector] = 0
    print("Adjusted interaction matrix to include all sectors.")
    return interaction_matrix[sorted(sectors)]

def scale_interaction_matrix(interaction_matrix):
    # Scale the interaction matrix using MinMaxScaler
    scaler = MinMaxScaler()
    scaled_matrix = scaler.fit_transform(interaction_matrix)
    print("Interaction matrix scaled.")
    return pd.DataFrame(scaled_matrix, index=interaction_matrix.index, columns=interaction_matrix.columns)

def calculate_cosine_similarity(matrix):
    # Calculate cosine similarity between sectors
    similarity = cosine_similarity(matrix.T)
    print("Cosine similarity calculated.")
    return similarity

def generate_hot_encoding(df, sectors):
    # Create a hot-encoded matrix from the dataframe
    hot_encoded = pd.get_dummies(df[['ACCT', 'Sector']], columns=['Sector'], prefix='', prefix_sep='').groupby('ACCT').max()
    print("Initial hot encoding generated.")
    
    # Adjust to ensure all defined sectors are included
    for sector in sectors:
        if sector not in hot_encoded.columns:
            hot_encoded[sector] = 0
    print("Adjusted hot encoding to include all sectors.")
    return hot_encoded[sorted(sectors)]

def get_recommendation_ranks(test_interaction_matrix, sector_similarity):
    # Calculate scores by dot product and rank them for recommendations
    scores = np.dot(test_interaction_matrix, sector_similarity)
    ranks = (-scores).argsort(axis=1).argsort(axis=1) + 1
    print("Recommendation ranks generated.")
    return pd.DataFrame(ranks, index=test_interaction_matrix.index, columns=test_interaction_matrix.columns)

def generate_transaction_ranks(df, sectors):
    # Generate transaction ranks based on the interaction matrix
    interaction_matrix = generate_interaction_matrix(df, sectors)
    transaction_ranks = interaction_matrix.rank(axis=1, method='max', ascending=False).astype(int)
    print("Transaction ranks generated.")
    return transaction_ranks

def main():
    df = load_and_preprocess_data('main6.csv')
    print("Data loaded and preprocessed.")
    
    split_date = pd.to_datetime("2023-01-01")
    sectors = sorted(df['Sector'].unique())
    print(f"Sectors identified: {sectors}")
    
    # Split the data into training and testing based on the date
    train_df, test_df = df[df['DATE'] < split_date], df[df['DATE'] >= split_date]
    print("Data split into training and testing sets.")
    
    # Process training and testing data
    train_interaction_matrix = generate_interaction_matrix(train_df, sectors)
    test_interaction_matrix = generate_interaction_matrix(test_df, sectors)
    print("Interaction matrices for training and testing generated.")
    
    # Scale the interaction matrices
    train_scaled = scale_interaction_matrix(train_interaction_matrix)
    test_scaled = scale_interaction_matrix(test_interaction_matrix)
    print("Scaled interaction matrices for training and testing.")
    
    # Calculate sector similarity from the training set
    sector_similarity = calculate_cosine_similarity(train_scaled)
    print("Sector similarity calculated.")
    
    # Generate hot encoding for training and testing sets
    train_hot_encoding = generate_hot_encoding(train_df, sectors)
    test_hot_encoding = generate_hot_encoding(test_df, sectors)
    print("Hot encoding for training and testing sets generated.")
    
    # Generate recommendations for the test set
    test_recommendations = get_recommendation_ranks(test_scaled, sector_similarity)
    print("Recommendations for the test set generated.")
    
    # Generate transaction ranks for the test set
    test_transaction_ranks = generate_transaction_ranks(test_df, sectors)
    print("Transaction ranks for the test set generated.")
    
    # Export results to Excel
    with pd.ExcelWriter('analysis_outputs.xlsx', engine='openpyxl') as writer:
        train_hot_encoding.to_excel(writer, sheet_name='Train Hot Encoding')
        test_hot_encoding.to_excel(writer, sheet_name='Test Hot Encoding')
        test_recommendations.to_excel(writer, sheet_name='Test Recommendations')
        test_transaction_ranks.to_excel(writer, sheet_name='Test Transaction Ranks')
    print("All requested outputs have been exported to 'analysis_outputs.xlsx'.")

if __name__ == "__main__":
    main()







isko try kro
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

def load_and_preprocess_data(filepath):
    try:
        df = pd.read_csv(filepath)
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df.dropna(inplace=True)
        return df
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

def generate_interaction_matrix(df):
    interaction_matrix = df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='sum', fill_value=0)
    return interaction_matrix

def generate_sector_similarity(interaction_matrix):
    scaler = MinMaxScaler()
    scaled_matrix = scaler.fit_transform(interaction_matrix)  # Scale interaction matrix without transposing
    sector_similarity = cosine_similarity(scaled_matrix.T)  # Calculate cosine similarity between sectors
    return pd.DataFrame(sector_similarity, index=interaction_matrix.columns, columns=interaction_matrix.columns)

def generate_hot_encoding(df, sectors):
    hot_encoded = df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc=lambda x: 1, fill_value=0)
    hot_encoded = hot_encoded.reindex(columns=sectors, fill_value=0)  # Ensure all sectors are included
    return hot_encoded

def get_recommendation_ranks(test_interaction_matrix, sector_similarity):
    # Dot product between test interactions and sector similarity to get a score matrix
    scores = np.dot(test_interaction_matrix, sector_similarity)
    # Convert scores to DataFrame for easier handling
    scores_df = pd.DataFrame(scores, index=test_interaction_matrix.index, columns=sector_similarity.columns)
    # Rank the sectors based on scores
    ranks = scores_df.apply(lambda x: (-x).argsort().argsort() + 1, axis=1)
    return ranks

def calculate_hit_rate(test_interaction_matrix, test_recommendations):
    hits = 0
    possible_hits = 0
    for acct in test_interaction_matrix.index:
        actual_sectors = test_interaction_matrix.loc[acct].loc[test_interaction_matrix.loc[acct] > 0].index
        recommended_sectors = test_recommendations.loc[acct].nsmallest(5).index
        hits += len(set(actual_sectors) & set(recommended_sectors))
        possible_hits += len(recommended_sectors)
    hit_rate = hits / possible_hits if possible_hits > 0 else 0
    return hit_rate

def main():
    df = load_and_preprocess_data('main6.csv')
    if df is None:
        return
    
    sectors = sorted(df['Sector'].unique())
    split_date = pd.to_datetime("2023-01-01")
    train_df, test_df = df[df['DATE'] < split_date], df[df['DATE'] >= split_date]

    train_interaction_matrix = generate_interaction_matrix(train_df)
    test_interaction_matrix = generate_interaction_matrix(test_df)
    
    sector_similarity = generate_sector_similarity(train_interaction_matrix)
    
    train_hot_encoding = generate_hot_encoding(train_df, sectors)
    test_hot_encoding = generate_hot_encoding(test_df, sectors)
    
    test_recommended_ranks = get_recommendation_ranks(test_interaction_matrix, sector_similarity)

    hit_rate = calculate_hit_rate(test_interaction_matrix, test_recommended_ranks)
    print(f"Hit Rate: {hit_rate:.2f}")

    with pd.ExcelWriter('complete_outputs.xlsx', engine='openpyxl') as writer:
        train_hot_encoding.to_excel(writer, sheet_name='Train Hot Encoding')
        test_hot_encoding.to_excel(writer, sheet_name='Test Hot Encoding')
        test_recommended_ranks.to_excel(writer, sheet_name='Test Recommended Ranks')

    print("All requested outputs have been exported to 'complete_outputs.xlsx'.")

if __name__ == "__main__":
    main()









import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

def load_and_preprocess_data(filepath):
    try:
        df = pd.read_csv(filepath)
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df.dropna(inplace=True)
        return df
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

def generate_interaction_matrix(df):
    return df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='sum', fill_value=0)

def generate_sector_similarity(interaction_matrix):
    scaler = MinMaxScaler()
    scaled_matrix = scaler.fit_transform(interaction_matrix.T)
    sector_similarity = cosine_similarity(scaled_matrix)
    return pd.DataFrame(sector_similarity, index=interaction_matrix.columns, columns=interaction_matrix.columns)

def generate_hot_encoding(df):
    hot_encoded = df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc=lambda x: 1, fill_value=0)
    return hot_encoded

def recommend_sectors(interaction_matrix, sector_similarity):
    scores = interaction_matrix.dot(sector_similarity)
    recommendations = scores.apply(lambda x: pd.Series(x.nlargest(5).index), axis=1)
    return recommendations

def main():
    df = load_and_preprocess_data('main6.csv')
    if df is None: return

    split_date = pd.to_datetime("2023-01-01")
    train_df, test_df = df[df['DATE'] < split_date], df[df['DATE'] >= split_date]

    # Generate sector-sector cosine similarity matrix from training data
    train_interaction_matrix = generate_interaction_matrix(train_df)
    sector_similarity = generate_sector_similarity(train_interaction_matrix)

    # Generate and export hot encoding for training and testing data
    train_hot_encoding = generate_hot_encoding(train_df)
    test_hot_encoding = generate_hot_encoding(test_df)

    # Generate sector recommendations for accounts in the test dataset
    test_interaction_matrix = generate_interaction_matrix(test_df)
    test_recommendations = recommend_sectors(test_interaction_matrix, sector_similarity)

    # Save outputs to Excel
    with pd.ExcelWriter('sector_analysis_outputs.xlsx', engine='openpyxl') as writer:
        train_hot_encoding.to_excel(writer, sheet_name='Train Hot Encoding')
        test_hot_encoding.to_excel(writer, sheet_name='Test Hot Encoding')
        test_recommendations.to_excel(writer, sheet_name='Test Recommendations')

    print("All outputs have been saved to 'sector_analysis_outputs.xlsx'.")

if __name__ == "__main__":
    main()






import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

def load_and_preprocess_data(filepath):
    try:
        df = pd.read_csv(filepath)
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df.dropna(inplace=True)
        return df
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

def generate_hot_encoding(df, sectors):
    hot_encoded = df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc=lambda x: 1, fill_value=0)
    for sector in sectors:
        if sector not in hot_encoded.columns:
            hot_encoded[sector] = 0
    return hot_encoded[sectors]  # Ensure consistent column order

def generate_ranks(df, sectors):
    interaction_counts = df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
    ranks = interaction_counts.rank(axis=1, method='max', ascending=False).astype(int)
    return ranks

def main():
    df = load_and_preprocess_data('main6.csv')
    if df is None:
        return

    split_date = pd.to_datetime("2023-01-01")
    train_df, test_df = df[df['DATE'] < split_date], df[df['DATE'] >= split_date]
    sectors = sorted(df['Sector'].unique())

    # Hot encoding for training and test data
    train_hot_encoded = generate_hot_encoding(train_df, sectors)
    test_hot_encoded = generate_hot_encoding(test_df, sectors)

    # Generate ranks for training data
    train_ranks = generate_ranks(train_df, sectors)

    with pd.ExcelWriter('outputs.xlsx', engine='openpyxl') as writer:
        train_hot_encoded.to_excel(writer, sheet_name='Train Data Hot Encoding')
        test_hot_encoded.to_excel(writer, sheet_name='Test Data Hot Encoding')
        train_ranks.to_excel(writer, sheet_name='Training Data Ranks')

    print("Exported all data to 'outputs.xlsx'.")

if __name__ == "__main__":
    main()





import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime

# Load and preprocess the dataset
def load_and_preprocess_data(filepath):
    try:
        df = pd.read_csv(filepath)
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df.dropna(inplace=True)
        return df
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Generate full recommendation ranks
def generate_full_ranks(interaction_matrix, sector_similarity_matrix, sectors):
    sector_ranks = pd.DataFrame(index=interaction_matrix.index, columns=sectors)
    for account in interaction_matrix.index:
        user_vector = interaction_matrix.loc[account].values.reshape(1, -1)
        user_sector_similarity = np.dot(user_vector, sector_similarity_matrix)
        
        # Determine ranks based on similarity scores
        sorted_indices = np.argsort(-user_sector_similarity).flatten()
        ranks = np.arange(1, len(sectors) + 1)[sorted_indices]
        
        for i, sector in enumerate(sectors):
            sector_ranks.at[account, sector] = ranks[i]
    
    return sector_ranks.astype(int)  # Ensure ranks are integers for correct `nsmallest` operation

# Evaluate recommendations
def evaluate_recommendations(test_df, all_sector_ranks):
    hits, total_recommendations = 0, 0
    for account in all_sector_ranks.index:
        # Ensure we're only evaluating accounts present in both training and test sets
        if account not in test_df['ACCT'].values:
            continue

        recommended_sectors = all_sector_ranks.loc[account].nsmallest(5).index.tolist()
        actual_sectors = test_df[test_df['ACCT'] == account]['Sector'].unique()
        hits += len(set(recommended_sectors) & set(actual_sectors))
        total_recommendations += len(recommended_sectors)
    
    hit_rate = hits / total_recommendations if total_recommendations else 0
    print(f"Hit Rate: {hit_rate:.2f}" if total_recommendations else "No recommendations were made.")

def main():
    df = load_and_preprocess_data('main6.csv')
    if df is None: return

    # Temporal split based on a specified date
    split_date = datetime(2023, 1, 1)
    train_df = df[df['DATE'] < split_date]
    test_df = df[df['DATE'] >= split_date]

    # Aggregate transaction counts by account and sector
    interaction_counts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
    scaler = MinMaxScaler()
    interaction_counts_normalized_train = scaler.fit_transform(interaction_counts_train)
    
    sectors = interaction_counts_train.columns.tolist()
    sector_similarity = cosine_similarity(interaction_counts_normalized_train)
    
    combined_interaction_df_train = pd.DataFrame(interaction_counts_normalized_train, index=interaction_counts_train.index, columns=sectors)
    all_sector_ranks = generate_full_ranks(combined_interaction_df_train, sector_similarity, sectors)

    # Exporting the results
    try:
        with pd.ExcelWriter('sector_recommendations_and_matrices.xlsx', engine='openpyxl') as writer:
            all_sector_ranks.to_excel(writer, sheet_name='Sector-wise Recommendation Ranks')
        print("Exported all data and recommendation ranks to 'sector_recommendations_and_matrices.xlsx'.")
    except Exception as e:
        print(f"Failed to export data: {e}")
    
    # Evaluate the model's predictive performance using the test dataset
    evaluate_recommendations(test_df, all_sector_ranks)

if __name__ == "__main__":
    main()








import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

# Function to load and preprocess the dataset
def load_and_preprocess_data(filepath):
    try:
        df = pd.read_csv(filepath)
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df.dropna(inplace=True)
        return df
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Generate full recommendation ranks
def generate_full_ranks(interaction_matrix, sector_similarity_matrix, sectors):
    sector_ranks = pd.DataFrame(index=interaction_matrix.index, columns=sectors)
    for account in interaction_matrix.index:
        user_vector = interaction_matrix.loc[account].values.reshape(1, -1)
        user_sector_similarity = np.dot(user_vector, sector_similarity_matrix)
        
        sorted_indices = np.argsort(-user_sector_similarity).flatten()
        sector_ranks.loc[account] = [np.where(sorted_indices == i)[0][0] + 1 for i in range(len(sectors))]
    
    return sector_ranks

# Evaluate recommendations against test data
def evaluate_recommendations(test_df, all_sector_ranks):
    hits = 0
    total_recommendations = 0
    
    for account in all_sector_ranks.index:
        recommended_sectors = all_sector_ranks.loc[account].nsmallest(5).index.tolist()
        actual_sectors = test_df[test_df['ACCT'] == account]['Sector'].unique()
        hits += len(set(recommended_sectors) & set(actual_sectors))
        total_recommendations += len(recommended_sectors)
    
    if total_recommendations > 0:
        hit_rate = hits / total_recommendations
        print(f"Hit Rate: {hit_rate:.2f}")
    else:
        print("No recommendations were made.")

def main():
    df = load_and_preprocess_data('main6.csv')
    if df is None:
        return

    # Temporal split for training and testing based on a chosen date
    split_date = pd.to_datetime("2023-01-01")
    train_df = df[df['DATE'] < split_date]
    test_df = df[df['DATE'] >= split_date]

    # Aggregate and normalize transaction data
    interaction_counts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
    scaler = MinMaxScaler()
    interaction_counts_normalized_train = scaler.fit_transform(interaction_counts_train)
    sectors = interaction_counts_train.columns.tolist()

    # Calculate similarity and generate ranks
    sector_similarity = cosine_similarity(interaction_counts_normalized_train.T)
    combined_interaction_df_train = pd.DataFrame(interaction_counts_normalized_train, index=interaction_counts_train.index, columns=sectors)
    all_sector_ranks = generate_full_ranks(combined_interaction_df_train, sector_similarity, sectors)

    # Exporting the results
    with pd.ExcelWriter('sector_recommendations_and_matrices.xlsx', engine='openpyxl') as writer:
        all_sector_ranks.to_excel(writer, sheet_name='Sector-wise Recommendation Ranks')
    print("Exported all data and recommendation ranks to 'sector_recommendations_and_matrices.xlsx'.")

    # Evaluate the model's predictive performance using test data
    evaluate_recommendations(test_df, all_sector_ranks)

if __name__ == "__main__":
    main()







import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

# Function to load and preprocess the dataset
def load_and_preprocess_data(filepath):
    try:
        df = pd.read_csv(filepath)
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        df.dropna(inplace=True)
        return df
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Function to generate full recommendation ranks
def generate_full_ranks(interaction_matrix, sector_similarity_matrix, sectors):
    sector_ranks = pd.DataFrame(index=interaction_matrix.index, columns=sectors)
    for account in interaction_matrix.index:
        user_vector = interaction_matrix.loc[account].values.reshape(1, -1)
        user_sector_similarity = np.dot(user_vector, sector_similarity_matrix)
        
        sorted_indices = np.argsort(-user_sector_similarity).flatten()
        sector_ranks.loc[account] = [np.where(sorted_indices == i)[0][0] + 1 for i in range(len(sectors))]
    
    return sector_ranks

# Function to evaluate recommendations
def evaluate_recommendations(test_df, all_sector_ranks):
    hits = 0
    total_recommendations = 0
    
    for account in all_sector_ranks.index:
        recommended_sectors = all_sector_ranks.loc[account].nsmallest(5).index.tolist()
        actual_sectors = test_df[test_df['ACCT'] == account]['Sector'].unique()
        hits += len(set(recommended_sectors) & set(actual_sectors))
        total_recommendations += len(recommended_sectors)
    
    if total_recommendations > 0:
        hit_rate = hits / total_recommendations
        print(f"Hit Rate: {hit_rate:.2f}")
    else:
        print("No recommendations were made.")

def main():
    df = load_and_preprocess_data('main6.csv')
    if df is None:
        return

    # Temporal split for training and testing
    split_date = pd.to_datetime("2023-01-01")  # Example split date
    train_df = df[df['DATE'] < split_date]
    test_df = df[df['DATE'] >= split_date]

    interaction_counts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
    scaler = MinMaxScaler()
    interaction_counts_normalized_train = scaler.fit_transform(interaction_counts_train)

    sectors = interaction_counts_train.columns.tolist()
    sector_similarity = cosine_similarity(interaction_counts_normalized_train.T)
    
    combined_interaction_df_train = pd.DataFrame(interaction_counts_normalized_train, index=interaction_counts_train.index, columns=sectors)
    all_sector_ranks = generate_full_ranks(combined_interaction_df_train, sector_similarity, sectors)

    # Exporting the results
    try:
        with pd.ExcelWriter('sector_recommendations_and_matrices.xlsx', engine='openpyxl') as writer:
            all_sector_ranks.to_excel(writer, sheet_name='Sector-wise Recommendation Ranks')
        print("Exported all data and recommendation ranks to 'sector_recommendations_and_matrices.xlsx'.")
    except Exception as e:
        print(f"Failed to export data: {e}")
    
    # Evaluate recommendations
    evaluate_recommendations(test_df, all_sector_ranks)

if __name__ == "__main__":
    main()










import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

# Function to load and preprocess the dataset
def load_and_preprocess_data(filepath):
    try:
        df = pd.read_csv(filepath)
        # Convert 'DATE' column to datetime format, handle errors by coercing invalid formats to NaT (Not a Time)
        df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')
        
        # Drop rows with any missing values
        df.dropna(inplace=True)
        
        return df
    except FileNotFoundError:
        print(f"File '{filepath}' not found.")
        return None
    except pd.errors.EmptyDataError:
        print("File is empty.")
        return None
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Generate full recommendation ranks for all sectors and accounts
def generate_full_ranks(interaction_matrix, sector_similarity_matrix, sectors):
    sector_ranks = pd.DataFrame(index=interaction_matrix.index, columns=sectors)
    for account in interaction_matrix.index:
        user_vector = interaction_matrix.loc[account].values.reshape(1, -1)
        user_sector_similarity = np.dot(user_vector, sector_similarity_matrix)
        
        # Ranking sectors based on similarity scores
        sorted_indices = np.argsort(-user_sector_similarity).flatten()
        sector_ranks.loc[account] = [np.where(sorted_indices == i)[0][0] + 1 for i in range(len(sectors))]
    
    return sector_ranks

def main():
    df = load_and_preprocess_data('main6.csv')
    if df is None:
        return

    unique_accounts = df['ACCT'].unique()
    train_accounts, test_accounts = train_test_split(unique_accounts, test_size=0.2, random_state=42)

    train_df = df[df['ACCT'].isin(train_accounts)]
    test_df = df[df['ACCT'].isin(test_accounts)]

    interaction_counts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
    scaler = MinMaxScaler()
    interaction_counts_normalized_train = scaler.fit_transform(interaction_counts_train)

    combined_interaction_train = interaction_counts_normalized_train
    sectors = interaction_counts_train.columns.tolist()

    sector_similarity = cosine_similarity(combined_interaction_train.T)
    
    combined_interaction_df_train = pd.DataFrame(combined_interaction_train, index=interaction_counts_train.index, columns=sectors)
    all_sector_ranks = generate_full_ranks(combined_interaction_df_train, sector_similarity, sectors)

    # Exporting the results
    try:
        with pd.ExcelWriter('sector_recommendations_and_matrices.xlsx', engine='openpyxl') as writer:
            all_sector_ranks.to_excel(writer, sheet_name='Sector-wise Recommendation Ranks')
        print("Exported all data and recommendation ranks to 'sector_recommendations_and_matrices.xlsx'.")
    except Exception as e:
        print(f"Failed to export data: {e}")

if __name__ == "__main__":
    main()











import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

# Load and preprocess the dataset
df = pd.read_csv('main6.csv')
df['DATE'] = pd.to_datetime(df['DATE'])

# Identify unique accounts and split into training and testing sets
unique_accounts = df['ACCT'].unique()
train_accounts, test_accounts = train_test_split(unique_accounts, test_size=0.2, random_state=42)

# Filter the dataset for training and testing
train_df = df[df['ACCT'].isin(train_accounts)]
test_df = df[df['ACCT'].isin(test_accounts)]

# Pivot to get interaction matrices and normalize
interaction_counts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
interaction_amounts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='sum', fill_value=0)
scaler = MinMaxScaler()
interaction_counts_normalized_train = scaler.fit_transform(interaction_counts_train)
interaction_amounts_normalized_train = scaler.fit_transform(interaction_amounts_train)

# Combine and calculate sector similarity
combined_interaction_train = (interaction_counts_normalized_train + interaction_amounts_normalized_train) / 2
sectors = interaction_counts_train.columns
sector_similarity = cosine_similarity(combined_interaction_train.T)

# Define a function to calculate ranks for all sectors for each customer
def calculate_sector_ranks(interaction_matrix, sector_similarity_matrix):
    sector_ranks = pd.DataFrame(index=interaction_matrix.index, columns=interaction_matrix.columns)
    for account in interaction_matrix.index:
        user_vector = interaction_matrix.loc[account].values.reshape(1, -1)
        user_sector_similarity = np.dot(user_vector, sector_similarity_matrix)[0]
        sorted_indices = np.argsort(-user_sector_similarity)
        ranks = np.empty_like(sorted_indices)
        ranks[sorted_indices] = np.arange(len(user_sector_similarity))
        sector_ranks.loc[account] = ranks + 1  # +1 to start ranking from 1 instead of 0
    return sector_ranks

# Calculate sector ranks for each customer
combined_interaction_df_train = pd.DataFrame(combined_interaction_train, index=interaction_counts_train.index, columns=sectors)
sector_ranks_df = calculate_sector_ranks(combined_interaction_df_train, sector_similarity)

# Exporting sector ranks
sector_ranks_df.to_csv('sector_ranks_per_customer.csv')

print("Exported sector ranks for each customer to 'sector_ranks_per_customer.csv'.")








import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

# Load and preprocess the dataset
df = pd.read_csv('main6.csv')
df['DATE'] = pd.to_datetime(df['DATE'])

# Identify unique accounts
unique_accounts = df['ACCT'].unique()

# Split unique accounts into training and testing sets
train_accounts, test_accounts = train_test_split(unique_accounts, test_size=0.2, random_state=42)

# Filter the original dataset to create training and testing datasets based on the split accounts
train_df = df[df['ACCT'].isin(train_accounts)]
test_df = df[df['ACCT'].isin(test_accounts)]

# Creating and normalizing interaction matrices for counts and amounts
interaction_counts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
interaction_amounts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='sum', fill_value=0)
scaler = MinMaxScaler()
interaction_counts_normalized_train = scaler.fit_transform(interaction_counts_train)
interaction_amounts_normalized_train = scaler.fit_transform(interaction_amounts_train)

# Hot encoding sectors for training data
hot_encoded_sectors_train = (interaction_counts_train > 0).astype(int)

# Combine normalized matrices with equal weight for each factor
combined_interaction_train = (interaction_counts_normalized_train + interaction_amounts_normalized_train) / 2
sectors = interaction_counts_train.columns

# Calculate the sector-to-sector similarity matrix from the combined interaction matrix
sector_similarity = cosine_similarity(combined_interaction_train.T)

# Generate recommendations and rank for all customers
def generate_recommendations_and_ranks(interaction_matrix, sector_similarity_matrix, sectors, top_n=5):
    recommendations = {}
    ranks = {}
    sector_names = sectors.tolist()
    for account in interaction_matrix.index:
        user_vector = interaction_matrix.loc[account].values.reshape(1, -1)
        user_sector_similarity = np.dot(user_vector, sector_similarity_matrix)[0]
        top_sector_indices = np.argsort(-user_sector_similarity)[:top_n]
        recommended_sectors = [sector_names[i] for i in top_sector_indices]
        recommendations[account] = recommended_sectors
        ranks[account] = np.sort(-user_sector_similarity)[:top_n] * -1
    return recommendations, ranks

combined_interaction_df_train = pd.DataFrame(combined_interaction_train, index=interaction_counts_train.index, columns=sectors)
all_recommendations, all_ranks = generate_recommendations_and_ranks(combined_interaction_df_train, sector_similarity, sectors)

# Hot encoding sectors for testing data
interaction_counts_test = test_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
hot_encoded_sectors_test = (interaction_counts_test > 0).astype(int)

# Exporting results, sector-wise analysis, and additional outputs
with pd.ExcelWriter('enhanced_sector_recommendations_and_matrices.xlsx', engine='openpyxl') as writer:
    # Original outputs
    # [Export code for Recommendations, Interaction Counts, etc., as before]

    # Additional outputs
    hot_encoded_sectors_train.to_excel(writer, sheet_name='Hot Encoded Sectors Train')
    hot_encoded_sectors_test.to_excel(writer, sheet_name='Hot Encoded Sectors Test')
    
    # Sector-wise recommendation rank for each customer
    pd.DataFrame.from_dict(all_ranks, orient='index', columns=[f'Rank {i+1}' for i in range(5)]).to_excel(writer, sheet_name='Recommendation Ranks')

print("Exported all data, recommendations, sector-wise analysis, and additional outputs to 'enhanced_sector_recommendations_and_matrices.xlsx'.")









import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
import openpyxl  # Ensure openpyxl is installed for Excel export

# Load the dataset
df = pd.read_csv('main6.csv')
df['DATE'] = pd.to_datetime(df['DATE'])  # Convert 'DATE' to datetime if needed

# Time-based split for training and testing
split_date = pd.Timestamp('2023-01-01')  # Adjust based on your dataset
train_df = df[df['DATE'] < split_date]
test_df = df[df['DATE'] >= split_date]

# Creating Interaction Matrices for Training Data (Counts and Amounts)
interaction_counts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='count', fill_value=0)
interaction_amounts_train = train_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='sum', fill_value=0)

# Normalize the interaction matrices
scaler = MinMaxScaler()
interaction_counts_normalized = scaler.fit_transform(interaction_counts_train)
interaction_amounts_normalized = scaler.fit_transform(interaction_amounts_train)

# Combine normalized matrices with equal weight for demonstration purposes
combined_interaction = (interaction_counts_normalized + interaction_amounts_normalized) / 2

# Calculate sector-to-sector similarity matrix from the combined interaction matrix
sector_similarity = cosine_similarity(combined_interaction.T)
sector_similarity_df = pd.DataFrame(sector_similarity, index=interaction_counts_train.columns, columns=interaction_counts_train.columns)

# Function to generate recommendations for all customers based on sector similarity
def generate_recommendations_for_all(interaction_matrix, sector_similarity_matrix, sectors, top_n=5):
    recommendations = {}
    for account in interaction_matrix.index:
        user_vector = interaction_matrix.loc[[account]].values
        user_sector_similarity = np.dot(user_vector, sector_similarity_matrix)[0]
        top_sector_indices = np.argsort(-user_sector_similarity)[:top_n]
        recommended_sectors = sectors[top_sector_indices].tolist()
        recommendations[account] = recommended_sectors
    return recommendations

# Generate recommendations for all customers
interaction_matrix_df = pd.DataFrame(combined_interaction, index=interaction_counts_train.index, columns=interaction_counts_train.columns)
sectors = interaction_counts_train.columns
all_recommendations = generate_recommendations_for_all(interaction_matrix_df, sector_similarity, sectors)

# Convert recommendations to DataFrame for export
recommendations_df = pd.DataFrame.from_dict(all_recommendations, orient='index', columns=[f'Top {i+1}' for i in range(5)])

# Prepare summary of actual amounts spent by each customer in each sector during the test period
actual_spending_test_period = test_df.pivot_table(index='ACCT', columns='Sector', values='TRAN_AMT', aggfunc='sum', fill_value=0)

# Initialize a DataFrame to store the comparison of actual spending in recommended sectors
comparison_df = pd.DataFrame(columns=['ACCT', 'Recommended Sectors', 'Actual Spending in Recommended Sectors'])

for acct, recommended_sectors in all_recommendations.items():
    if acct in actual_spending_test_period.index:
        actual_spending = actual_spending_test_period.loc[acct, recommended_sectors].sum()
    else:
        actual_spending = 0
    comparison_df = comparison_df.append({
        'ACCT': acct,
        'Recommended Sectors': ', '.join(recommended_sectors),
        'Actual Spending in Recommended Sectors': actual_spending
    }, ignore_index=True)

# Export to Excel with separate sheets
with pd.ExcelWriter('recommendations_and_matrices.xlsx', engine='openpyxl') as writer:
    recommendations_df.to_excel(writer, sheet_name='Customer Recommendations')
    interaction_counts_train.to_excel(writer, sheet_name='Interaction Counts Train')
    interaction_amounts_train.to_excel(writer, sheet_name='Interaction Amounts Train')
    sector_similarity_df.to_excel(writer, sheet_name='Sector Similarity')
    comparison_df.to_excel(writer, sheet_name='Spending Comparison')

print("Exported all data to 'recommendations_and_matrices.xlsx'.")
